{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 13:56:09.253340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-20 13:56:09.276514: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-20 13:56:09.283659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 13:56:09.302611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-20 13:56:12.149747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "sys.path.append('/work/users/d/d/ddinh/aaco/src')\n",
    "from load_dataset import load_adni_data\n",
    "from cvar_sensing.utils import prepare_time_series, batch_interp_nd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 20, 4) (320, 20, 4) (400, 20, 4)\n",
      "(1280, 20, 1) (320, 20, 1) (400, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/work/users/d/d/ddinh/aaco/input_data/synthetic_data.npz')\n",
    "\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# split into 64/16/20\n",
    "n = len(x)\n",
    "n_train = int(n * 0.64)\n",
    "n_val = int(n * 0.16)\n",
    "n_test = n - n_train - n_val\n",
    "\n",
    "# shuffle\n",
    "idx = np.random.permutation(n)\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "\n",
    "train_x = x[:n_train]\n",
    "train_y = y[:n_train]\n",
    "val_x = x[n_train:n_train + n_val]\n",
    "val_y = y[n_train:n_train + n_val]\n",
    "test_x = x[n_train + n_val:]\n",
    "test_y = y[n_train + n_val:]\n",
    "\n",
    "num_ts = train_x.shape[1]\n",
    "\n",
    "print(train_x.shape, val_x.shape, test_x.shape)\n",
    "print(train_y.shape, val_y.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts(x, y): \n",
    "    x_data = np.copy(x)\n",
    "    y_data = np.copy(y)\n",
    "    x_ts = []\n",
    "    y_ts = []\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(num_ts):\n",
    "        x_zero = np.zeros(x_data.shape)\n",
    "        x_zero[:, :i+1] = x_data[:, :i+1,:]\n",
    "        \n",
    "        x_filtered = np.transpose(x_zero, (0, 2, 1)).reshape(-1, x_data.shape[1] * x_data.shape[2])\n",
    "        \n",
    "        # zero_mask = np.zeros(x_zero[non_zero_mask,:,:].shape)\n",
    "        # zero_mask[:,:i+1] = 1\n",
    "        # zero_mask = np.transpose(zero_mask, (0, 2, 1)).reshape(-1, x_data.shape[1] * x_data.shape[2])\n",
    "        \n",
    "        # x_filtered = np.concatenate([x_filtered, zero_mask], axis=1)\n",
    "        x_filtered = np.concatenate([x_filtered, np.repeat(i, x_filtered.shape[0])[:, None]], axis=1)\n",
    "        \n",
    "        x_ts.append(x_filtered)\n",
    "        y_ts.append(y_data[:, i, :])\n",
    "        \n",
    "    x_ts = np.concatenate(x_ts, axis=0)\n",
    "    y_ts = np.concatenate(y_ts, axis=0)\n",
    "    \n",
    "    return x_ts, y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25600, 81), (25600, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ts, train_y_ts = get_ts(train_x, train_y)\n",
    "val_x_ts, val_y_ts = get_ts(val_x, val_y)\n",
    "test_x_ts, test_y_ts = get_ts(test_x, test_y)\n",
    "\n",
    "# concatenate train and val\n",
    "# train_x_ts = np.concatenate([train_x_ts, val_x_ts], axis=0)\n",
    "# train_y_ts = np.concatenate([train_y_ts, val_y_ts], axis=0)\n",
    "\n",
    "train_x_ts.shape, train_y_ts.shape\n",
    "# ((7704, 49), (7704, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m X_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([train_x_ts]\u001b[38;5;241m*\u001b[39mmasksper, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m Y_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([train_y_ts]\u001b[38;5;241m*\u001b[39mmasksper, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m----> 6\u001b[0m \u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      7\u001b[0m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(B\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     10\u001b[0m zero_mask \u001b[38;5;241m=\u001b[39m X_class[:,:d] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m X_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([train_x_ts]\u001b[38;5;241m*\u001b[39mmasksper, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m Y_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([train_y_ts]\u001b[38;5;241m*\u001b[39mmasksper, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m----> 6\u001b[0m [np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(np\u001b[38;5;241m.\u001b[39meye(d))[:, :np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(d)], \u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_class\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])],\n\u001b[1;32m      7\u001b[0m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(B\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     10\u001b[0m zero_mask \u001b[38;5;241m=\u001b[39m X_class[:,:d] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "masksper = 256 \n",
    "d = train_x_ts.shape[1] - 1\n",
    "X_class = np.concatenate([train_x_ts]*masksper, 0)\n",
    "Y_class = np.concatenate([train_y_ts]*masksper, 0)\n",
    "B = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class.shape[0])],\n",
    "1)\n",
    "B = np.float32(B.T)\n",
    "\n",
    "zero_mask = X_class[:,:d] == 0\n",
    "B[zero_mask] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero = np.sum(B, axis=1) != 0\n",
    "B = B[mask_nonzero]\n",
    "X_class = X_class[mask_nonzero]\n",
    "Y_class = Y_class[mask_nonzero]\n",
    "\n",
    "X_class[:,:d] = X_class[:,:d] * B\n",
    "X_class.shape, Y_class.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_zero[:, i+1:] = np.nan\n",
    "# x_zero = prepare_input(torch.Tensor([range(0,num_ts)] * x_zero.shape[0]), torch.Tensor(x_zero))[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30688, 81), (30688, 1), (30688, 81))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masksper = 5\n",
    "d = val_x_ts.shape[1]\n",
    "X_class_val = np.concatenate([val_x_ts]*masksper, 0)\n",
    "Y_class_val = np.concatenate([val_y_ts]*masksper, 0)\n",
    "B_val = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class_val.shape[0])],\n",
    "1)\n",
    "B_val = np.float32(B_val.T)\n",
    "\n",
    "# B_val = np.ones_like(B_val)\n",
    "\n",
    "zero_mask_val = X_class_val[:,:d] == 0\n",
    "B_val[zero_mask_val] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero_val = np.sum(B_val, axis=1) != 0\n",
    "B_val = B_val[mask_nonzero_val]\n",
    "X_class_val = X_class_val[mask_nonzero_val]\n",
    "Y_class_val = Y_class_val[mask_nonzero_val]\n",
    "\n",
    "X_class_val[:,:d] = X_class_val[:,:d] * B_val\n",
    "X_class_val.shape, Y_class_val.shape, B_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m196353/196355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9318 - loss: 0.2362 - prc: 0.2866 - roc_auc: 0.6751\n",
      "Epoch 1: val_roc_auc improved from -inf to 0.60838, saving model to /work/users/d/d/ddinh/aaco/models/mlp_interpolation.keras\n",
      "\u001b[1m196355/196355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 849us/step - accuracy: 0.9318 - loss: 0.2362 - prc: 0.2866 - roc_auc: 0.6751 - val_accuracy: 0.9240 - val_loss: 0.2806 - val_prc: 0.2718 - val_roc_auc: 0.6084\n",
      "Epoch 2/100\n",
      "\u001b[1m196335/196355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9328 - loss: 0.2314 - prc: 0.3077 - roc_auc: 0.6959\n",
      "Epoch 2: val_roc_auc improved from 0.60838 to 0.61031, saving model to /work/users/d/d/ddinh/aaco/models/mlp_interpolation.keras\n",
      "\u001b[1m196355/196355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 850us/step - accuracy: 0.9328 - loss: 0.2314 - prc: 0.3077 - roc_auc: 0.6960 - val_accuracy: 0.9248 - val_loss: 0.2876 - val_prc: 0.2759 - val_roc_auc: 0.6103\n",
      "Epoch 3/100\n",
      "\u001b[1m196335/196355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9332 - loss: 0.2302 - prc: 0.3130 - roc_auc: 0.7004\n",
      "Epoch 3: val_roc_auc did not improve from 0.61031\n",
      "\u001b[1m196355/196355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 824us/step - accuracy: 0.9332 - loss: 0.2302 - prc: 0.3130 - roc_auc: 0.7004 - val_accuracy: 0.9244 - val_loss: 0.3028 - val_prc: 0.2765 - val_roc_auc: 0.6080\n",
      "Epoch 4/100\n",
      "\u001b[1m 90196/196355\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 825us/step - accuracy: 0.9336 - loss: 0.2289 - prc: 0.3182 - roc_auc: 0.7042"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "TOTAL_FEATURES = train_x_ts.shape[-1]\n",
    "HIDDEN_DIM = 15\n",
    "NUM_CLASSES = 1 \n",
    "DROPOUT_RATE = 0.75\n",
    "\n",
    "def create_mlp():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(TOTAL_FEATURES,)),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        # layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        # layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(NUM_CLASSES, activation='sigmoid') \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = create_mlp()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', AUC(name='roc_auc'), AUC(name='prc', curve='PR')]\n",
    ")\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        '/work/users/d/d/ddinh/aaco/models/mlp_interpolation.keras',  \n",
    "        monitor='val_roc_auc',\n",
    "        mode='max',  \n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_roc_auc', \n",
    "        mode='max', \n",
    "        patience=10,  \n",
    "        verbose=1\n",
    "    )\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[checkpoint, early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    loss, accuracy, roc_auc, prc = model.evaluate(X, y, verbose=0)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}, ROC AUC: {roc_auc}, PRC: {prc}\")\n",
    "    return loss, accuracy, roc_auc\n",
    "\n",
    "# history = train_model(model, train_x_ts, train_y_ts, val_x_ts, val_y_ts)\n",
    "# evaluate_model(model, val_x_ts, val_y_ts)\n",
    "history = train_model(model, X_class, Y_class, X_class_val, Y_class_val)\n",
    "evaluate_model(model, X_class_val, Y_class_val)\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['roc_auc'])\n",
    "    plt.plot(history.history['val_roc_auc'])\n",
    "    plt.title('model roc_auc')\n",
    "    plt.ylabel('roc_auc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['prc'])\n",
    "    plt.plot(history.history['val_prc'])\n",
    "    plt.title('model prc')\n",
    "    plt.ylabel('prc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_history(history)\n",
    "#  val_prc: 0.5998 - val_roc_auc: 0.7917\n",
    "# val_accuracy: 0.5886 - val_loss: 0.8313 - val_prc: 0.5985 - val_roc_auc: 0.7912\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_adni_data()\n",
    "x = dataset.x\n",
    "y = dataset.y\n",
    "\n",
    "mask_nan = np.isnan(x)\n",
    "\n",
    "x[mask_nan] = 0\n",
    "\n",
    "num_ts = y.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06387226 0.64271457 0.29341317]\n",
      "[0.08805668 0.61234818 0.29959514]\n",
      "[0.10761421 0.59187817 0.30050761]\n",
      "[0.125      0.58974359 0.28525641]\n",
      "[0.16613757 0.54179894 0.29206349]\n",
      "[0.13573883 0.56872852 0.29553265]\n",
      "[0.178125  0.5796875 0.2421875]\n",
      "[0.18283582 0.53731343 0.27985075]\n",
      "[0.17350746 0.46455224 0.3619403 ]\n",
      "[0.18235294 0.45294118 0.36470588]\n",
      "[0.18596491 0.49473684 0.31929825]\n",
      "[0.17098446 0.43005181 0.39896373]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_ts):\n",
    "    count = [0,0,0]\n",
    "    total = 0\n",
    "    for j in range(y.shape[0]):\n",
    "        for k in range(3):\n",
    "            if y[j,i,k] == 1:\n",
    "                count[k] += 1\n",
    "                total += 1\n",
    "    count = np.array(count)\n",
    "    print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13054449 0.56998672 0.29946879]\n"
     ]
    }
   ],
   "source": [
    "count = [0,0,0]\n",
    "total = 0\n",
    "for i in range(num_ts):\n",
    "    for j in range(y.shape[0]):\n",
    "        for k in range(3):\n",
    "            if y[j,i,k] == 1:\n",
    "                count[k] += 1\n",
    "                total += 1\n",
    "count = np.array(count)\n",
    "print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40976380572188953"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_nan = x==0\n",
    "# get the number of nan values\n",
    "total = mask_nan.sum()\n",
    "probability = total / x.size\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((801, 12, 4), (201, 12, 4), (801, 12, 3), (201, 12, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into train and test sets 80/20 with random seed 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = prepare_time_series(torch.Tensor([range(0,12)] * x_train.shape[0]), torch.Tensor(x_train))[1]\n",
    "y_train = prepare_time_series(torch.Tensor([range(0,12)] * y_train.shape[0]), torch.Tensor(y_train))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3297,  0.1390,  1.3199, -0.0833],\n",
       "        [ 0.3297,  0.1390,  1.0883,  0.3012],\n",
       "        [ 0.3297,  0.1390,  0.9298, -0.1822],\n",
       "        [ 0.3297,  0.1390,  0.9298, -0.1822],\n",
       "        [ 0.3297,  0.0346,  0.9745,  0.2414],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3297,  0.0346,  0.9745,  0.2414],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3297,  0.4605,  0.9745,  0.2414],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = torch.cat([x_train, x_train[:, [-1]]], dim=-2).numpy()\n",
    "# y_train = torch.cat([y_train, y_train[:, [-1]]], dim=-2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.round(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ts = []\n",
    "# y_ts = []\n",
    "\n",
    "# for i in range(num_ts): \n",
    "#     x_temp = np.zeros_like(x_train)\n",
    "#     x_temp[:, :i+1, :] = x_train[:, :i+1, :]\n",
    "#     x_ts.append(x_temp)    \n",
    "#     y_ts.append(y_train)\n",
    "# x_ts = np.concatenate(x_ts, axis=0)\n",
    "# y_ts = np.concatenate(y_ts, axis=0)\n",
    "# x_ts.shape, y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"temp\n",
    "\"\"\"\n",
    "x_ts = x_train\n",
    "y_ts = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "for item in x_ts:\n",
    "    x_all.append(item.flatten('F'))\n",
    "x_train = np.array(x_all)\n",
    "y_train = y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_masks(inputs, pm=0.2, pd_m=0.4):\n",
    "    inputs = np.copy(inputs).reshape(-1, 12, 4)\n",
    "    n, T, M = inputs.shape\n",
    "    masked_inputs = inputs.copy()\n",
    "\n",
    "    mask_m1 = np.random.binomial(1, pm, size=(n, T, M))\n",
    "    \n",
    "    t_max = np.random.randint(0, T, size=n)\n",
    "    mask_m2 = np.ones((n, T, M))\n",
    "    for i in range(n):\n",
    "        mask_m2[i, t_max[i]:] = 0\n",
    "    \n",
    "    modality_drop = np.random.binomial(1, pd_m, size=(n, M))\n",
    "    mask_m3 = np.ones((n, T, M))\n",
    "    for m in range(M):\n",
    "        mask_m3[:, :, m] *= modality_drop[:, m].reshape(-1, 1)\n",
    "\n",
    "    final_mask = mask_m1 * mask_m2 * mask_m3\n",
    "    masked_inputs *= final_mask\n",
    "\n",
    "    return masked_inputs, final_mask.reshape(n, -1)\n",
    "\n",
    "pm = 0.2\n",
    "pd_m = 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masksper = 256 * 2\n",
    "d = x_train.shape[1]\n",
    "X_class = np.concatenate([x_train]*masksper, 0)\n",
    "Y_class = np.concatenate([y_train]*masksper, 0)\n",
    "# B = np.concatenate(\n",
    "# [np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class.shape[0])],\n",
    "# 1)\n",
    "# B = np.float32(B.T)\n",
    "\n",
    "_, B = apply_masks(X_class, pm, pd_m)\n",
    "    \n",
    "\"\"\"\n",
    "remove for interpolation\n",
    "\"\"\"\n",
    "zero_mask = X_class == 0\n",
    "B[zero_mask] = 0\n",
    "\n",
    "# # remove 0 mask\n",
    "mask_nonzero = np.sum(B, axis=1) != 0\n",
    "B = B[mask_nonzero]\n",
    "X_class = X_class[mask_nonzero]\n",
    "Y_class = Y_class[mask_nonzero]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_nan = X_class == 0\n",
    "# B[mask_nan] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = np.concatenate((X_class*B, B), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class.shape, Y_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "for i in range(B.shape[0]):\n",
    "    b = B[i]\n",
    "    temp = -1\n",
    "    for j in range(4):\n",
    "        part = b[num_ts*j:num_ts*(j+1)]\n",
    "        max_index = np.where(part == 1)[0]\n",
    "        if len(max_index) > 0:\n",
    "            max_index = max_index[-1]\n",
    "            if max_index > temp:\n",
    "                temp = max_index\n",
    "    location.append(temp)\n",
    "    \n",
    "location = np.array(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(location, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = []\n",
    "for i in range(Y_class.shape[0]):\n",
    "    y_location = Y_class[i, location[i]]\n",
    "    mask_nan = np.isnan(y_location)\n",
    "    y_location[mask_nan] = 0\n",
    "    y_temp.append(y_location)\n",
    "y_temp = np.array(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove y with nan values\n",
    "mask_zero = np.sum(y_temp, axis=1) != 0\n",
    "X_class = X_class[mask_zero]\n",
    "Y_class = y_temp[mask_zero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_class = np.argmax(Y_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "est = XGBClassifier(n_estimators=256, device='gpu')\n",
    "est.fit(X_class, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est.save_model('/work/users/d/d/ddinh/aaco/models/adni_different_masking.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts_val = []\n",
    "y_ts_val = []\n",
    "\n",
    "for i in range(num_ts): \n",
    "    x_temp = np.zeros_like(x_val)\n",
    "    x_temp[:, :i+1, :] = x_val[:, :i+1, :]\n",
    "    x_ts_val.append(x_temp)    \n",
    "    y_ts_val.append(y_val)\n",
    "x_ts_val = np.concatenate(x_ts_val, axis=0)\n",
    "y_ts_val = np.concatenate(y_ts_val, axis=0)\n",
    "x_ts_val.shape, y_ts_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_val = []\n",
    "for item in x_ts_val:\n",
    "    x_all_val.append(item.flatten('F'))\n",
    "x_val = np.array(x_all_val)\n",
    "y_val = y_ts_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masksper = 1\n",
    "d = x_val.shape[1]\n",
    "X_class_val = np.concatenate([x_val]*masksper, 0)\n",
    "Y_class_val = np.concatenate([y_val]*masksper, 0)\n",
    "B_val = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class_val.shape[0])],\n",
    "1)\n",
    "B_val = np.float32(B_val.T)\n",
    "\n",
    "# B_val = np.ones_like(B_val)\n",
    "\n",
    "zero_mask_val = X_class_val == 0\n",
    "B_val[zero_mask_val] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero_val = np.sum(B_val, axis=1) != 0\n",
    "B_val = B_val[mask_nonzero_val]\n",
    "X_class_val = X_class_val[mask_nonzero_val]\n",
    "Y_class_val = Y_class_val[mask_nonzero_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_val = []\n",
    "for i in range(B_val.shape[0]):\n",
    "    b = B_val[i]\n",
    "    temp = -1\n",
    "    for j in range(4):\n",
    "        part = b[num_ts*j:num_ts*(j+1)]\n",
    "        max_index = np.where(part == 1)[0]\n",
    "        if len(max_index) > 0:\n",
    "            max_index = max_index[-1]\n",
    "            if max_index > temp:\n",
    "                temp = max_index\n",
    "    location_val.append(temp)\n",
    "    \n",
    "location_val = np.array(location_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp_val = []\n",
    "for i in range(Y_class_val.shape[0]):\n",
    "    y_location_val = Y_class_val[i, location_val[i]]\n",
    "    mask_nan_val = np.isnan(y_location_val)\n",
    "    y_location_val[mask_nan_val] = 0\n",
    "    y_temp_val.append(y_location_val)\n",
    "y_temp_val = np.array(y_temp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove y with nan values for validation set\n",
    "mask_zero_val = np.sum(y_temp_val, axis=1) != 0\n",
    "X_class_val = X_class_val[mask_zero_val]\n",
    "Y_class_val = y_temp_val[mask_zero_val]\n",
    "B_val = B_val[mask_zero_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_zero_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_val = np.concatenate((X_class_val*B_val, B_val), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = est.predict_proba(X_class_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.argmax(val_preds, 1)==np.argmax(Y_class_val, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is temoprary evaluation, since it's not really correct.\n",
    "# it should be evaluated on the accumulated predictions, not the individual predictions like this rolling out \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "pr_auc_macro = average_precision_score(Y_class_val, val_preds, average=\"macro\")\n",
    "print(pr_auc_macro)\n",
    "\n",
    "roc_auc_macro = roc_auc_score(Y_class_val, val_preds, average=\"macro\", multi_class=\"ovr\")\n",
    "print(roc_auc_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(B_val.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "# 0.5057228523811975\n",
    "# 0.6798018971723648\n",
    "\n",
    "# masking from a2mt paper\n",
    "# 0.5109105973299515\n",
    "# 0.7030657167468642"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
