{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 12:44:04.415740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-07 12:44:04.792254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-07 12:44:04.892507: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-07 12:44:05.617770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-07 12:44:11.484388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "sys.path.append('/work/users/d/d/ddinh/aaco/src')\n",
    "from load_dataset import load_adni_data\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_digits = np.load('/work/users/d/d/ddinh/aaco/input_data/Synthetic_raw/train_digits.npy')\n",
    "# X_train_counter = np.load('/work/users/d/d/ddinh/aaco/input_data/Synthetic_raw/train_counter.npy')\n",
    "# y_train = np.load('/work/users/d/d/ddinh/aaco/input_data/Synthetic_raw/train_labels.npy')\n",
    "# X_test_digits = np.load('/work/users/d/d/ddinh/aaco/input_data/Synthetic_raw/test_digits.npy')\n",
    "# X_test_counter = np.load('/work/users/d/d/ddinh/aaco/input_data/Synthetic_raw/test_counter.npy')\n",
    "# y_test = np.load('/work/users/d/d/ddinh/aaco/input_data/Synthetic_raw/test_labels.npy')\n",
    "\n",
    "X_train_digits = np.load('/work/users/d/d/ddinh/aaco/input_data/pca_digits/train_digits_images.npy')\n",
    "X_train_counter = np.load('/work/users/d/d/ddinh/aaco/input_data/pca_digits/train_counter_images.npy')\n",
    "y_train = np.load('/work/users/d/d/ddinh/aaco/input_data/pca_digits/train_labels.npy')\n",
    "X_test_digits = np.load('/work/users/d/d/ddinh/aaco/input_data/pca_digits/test_digits_images.npy')\n",
    "X_test_counter = np.load('/work/users/d/d/ddinh/aaco/input_data/pca_digits/test_counter_images.npy')\n",
    "y_test = np.load('/work/users/d/d/ddinh/aaco/input_data/pca_digits/test_labels.npy')\n",
    "\n",
    "y_train = np.eye(np.max(y_train) + 1)[y_train]\n",
    "y_test = np.eye(np.max(y_test) + 1)[y_test]\n",
    "\n",
    "X_train = np.concatenate([X_train_digits, X_train_counter], axis=1)\n",
    "X_test = np.concatenate([X_test_digits, X_test_counter], axis=1)\n",
    "\n",
    "num_ts = 10\n",
    "Xval = X_test\n",
    "Yval = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pt file \n",
    "import torch \n",
    "# path = '/work/users/d/d/ddinh/aaco/results/dataset_adnimlp_imputation_exclude_nan_mask_less_features.pt'\n",
    "# path = '/work/users/d/d/ddinh/aaco/results/dataset_synthetic_raw_siamese_0.03.pt'\n",
    "# path = '/work/users/d/d/ddinh/aaco/results/dataset_synthetic_raw_xgb_0.025.pt'\n",
    "path = '/work/users/d/d/ddinh/aaco/results/dataset_synthetic_pca_xgb_0.03.pt'\n",
    "data = torch.load(path)\n",
    "x = data['X']\n",
    "y = data['y']\n",
    "mask = data['mask']\n",
    "action = data['Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_action = []\n",
    "count = 0\n",
    "for i in range(action.shape[0]):\n",
    "    if action[i, 0] == 1:\n",
    "        merge_action.append(action[i])\n",
    "        count += 1\n",
    "    else:\n",
    "        merge_action[count - 1] += action[i]\n",
    "merge_action = np.array(merge_action)\n",
    "merge_action = merge_action[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# model = tf.keras.models.load_model('/work/users/d/d/ddinh/aaco/models/mlp.keras')\n",
    "model = XGBClassifier()\n",
    "# model.load_model('/work/users/d/d/ddinh/aaco/models/synthetic_raw.model')\n",
    "model.load_model('/work/users/d/d/ddinh/aaco/models/synthetic_pca.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = merge_action.shape[0]\n",
    "merge_action = merge_action[:current]\n",
    "Xval = Xval[:current]\n",
    "Yval = Yval[:current]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = 24\n",
    "# B = np.concatenate(\n",
    "# [np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(6)], 1, keepdims=True) for _ in range(merge_action.shape[0])],\n",
    "# 1)\n",
    "# B = np.float32(B.T)\n",
    "# # B = np.expand_dims(B, axis=-1)\n",
    "\n",
    "# merge_action = B\n",
    "# np.sum(merge_action, 1).mean()\n",
    "# merge_action = np.ones_like(merge_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9026818181818181\n"
     ]
    }
   ],
   "source": [
    "x_input = (Xval*merge_action[:,:,None]).reshape(Xval.shape[0], -1)\n",
    "Xvalmasked = np.concatenate((x_input, merge_action), 1)\n",
    "val_preds = model.predict_proba(Xvalmasked) \n",
    "print(np.mean(np.round(val_preds)==Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.712559986114502, 0.6570899963378907)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(merge_action[:,:10], 1).mean() / 10, np.sum(merge_action[:,10:], 1).mean() / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (1846374165.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    0.02: 1800\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "# raw \n",
    "0.02: 1800\n",
    "0.9496969696969697\n",
    "(0.6128333568572998, 0.530388879776001)\n",
    "\n",
    "\n",
    "0.025: 2400 samples\n",
    "0.9451515151515152\n",
    "(0.5213749885559082, 0.4473750114440918)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (2052525778.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[48], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    0.02: 1800 samples\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "# siamese: \n",
    "0.02: 1800 samples\n",
    "0.949040404040404    \n",
    "(0.6426111221313476, 0.5537777900695801)\n",
    "\n",
    "0.025: 2400 samples\n",
    "0.9410227272727273\n",
    "(0.4872499942779541, 0.42216668128967283)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
