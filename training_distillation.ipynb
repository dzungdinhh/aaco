{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 13:17:58.060438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 13:17:58.082402: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 13:17:58.089211: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 13:17:58.106382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-01 13:18:00.270913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "sys.path.append('/work/users/d/d/ddinh/aaco/src')\n",
    "from load_dataset import load_adni_data\n",
    "from cvar_sensing.utils import prepare_time_series, batch_interp_nd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    ds = load_adni_data(file_path=file_path)\n",
    "    x = ds.x\n",
    "    y = ds.y\n",
    "    mask_nan = np.isnan(x)\n",
    "    x[mask_nan] = 0\n",
    "    \n",
    "    mask_nan_y = np.isnan(y)\n",
    "    y[mask_nan_y] = 0\n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = load_data(\"/work/users/d/d/ddinh/aaco/input_data/train_data.npz\")\n",
    "val_x, val_y = load_data(\"/work/users/d/d/ddinh/aaco/input_data/val_data.npz\")\n",
    "test_x, test_y = load_data(\"/work/users/d/d/ddinh/aaco/input_data/test_data.npz\")\n",
    "\n",
    "num_ts = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts(x, y): \n",
    "    x_data = np.copy(x)\n",
    "    y_data = np.copy(y)\n",
    "    x_ts = []\n",
    "    y_ts = []\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(num_ts):\n",
    "        x_zero = np.zeros(x_data.shape)\n",
    "        x_zero[:, :i+1] = x_data[:, :i+1,:]\n",
    "        \n",
    "        non_zero_mask = np.sum(y_data[:,i,:], axis=1) != 0\n",
    "        \n",
    "        x_filtered = np.transpose(x_zero[non_zero_mask,:,:], (0, 2, 1)).reshape(-1, x_data.shape[1] * x_data.shape[2])\n",
    "        \n",
    "        # zero_mask = np.zeros(x_zero[non_zero_mask,:,:].shape)\n",
    "        # zero_mask[:,:i+1] = 1\n",
    "        # zero_mask = np.transpose(zero_mask, (0, 2, 1)).reshape(-1, x_data.shape[1] * x_data.shape[2])\n",
    "        \n",
    "        # x_filtered = np.concatenate([x_filtered, zero_mask], axis=1)\n",
    "        x_filtered = np.concatenate([x_filtered, np.repeat(i, x_filtered.shape[0])[:, None]], axis=1)\n",
    "        \n",
    "        x_ts.append(x_filtered)\n",
    "        y_ts.append(y_data[non_zero_mask, i, :])\n",
    "        \n",
    "    x_ts = np.concatenate(x_ts, axis=0)\n",
    "    y_ts = np.concatenate(y_ts, axis=0)\n",
    "    \n",
    "    return x_ts, y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4828, 49), (4828, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ts, train_y_ts = get_ts(train_x, train_y)\n",
    "val_x_ts, val_y_ts = get_ts(val_x, val_y)\n",
    "test_x_ts, test_y_ts = get_ts(test_x, test_y)\n",
    "\n",
    "# concatenate train and val\n",
    "# train_x_ts = np.concatenate([train_x_ts, val_x_ts], axis=0)\n",
    "# train_y_ts = np.concatenate([train_y_ts, val_y_ts], axis=0)\n",
    "\n",
    "train_x_ts.shape, train_y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1132593, 49), (1132593, 3), (1132593, 48))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masksper = 256 \n",
    "d = train_x_ts.shape[1] - 1\n",
    "X_class = np.concatenate([train_x_ts]*masksper, 0)\n",
    "Y_class = np.concatenate([train_y_ts]*masksper, 0)\n",
    "\n",
    "X_class_teacher = np.copy(X_class)\n",
    "Y_class_teacher = np.copy(Y_class)\n",
    "B = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class.shape[0])],\n",
    "1)\n",
    "B = np.float32(B.T)\n",
    "\n",
    "zero_mask = X_class[:,:d] == 0\n",
    "B[zero_mask] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero = np.sum(B, axis=1) != 0\n",
    "B = B[mask_nonzero]\n",
    "X_class = X_class[mask_nonzero]\n",
    "Y_class = Y_class[mask_nonzero]\n",
    "\n",
    "X_class_teacher = X_class_teacher[mask_nonzero]\n",
    "Y_class_teacher = Y_class_teacher[mask_nonzero]\n",
    "\n",
    "X_class[:,:d] = X_class[:,:d] * B\n",
    "X_class.shape, Y_class.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5609, 49), (5609, 3), (5609, 49))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masksper = 5\n",
    "d = val_x_ts.shape[1]\n",
    "X_class_val = np.concatenate([val_x_ts]*masksper, 0)\n",
    "Y_class_val = np.concatenate([val_y_ts]*masksper, 0)\n",
    "\n",
    "X_class_teacher_val = np.copy(X_class_val)\n",
    "Y_class_teacher_val = np.copy(Y_class_val)\n",
    "\n",
    "B_val = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class_val.shape[0])],\n",
    "1)\n",
    "B_val = np.float32(B_val.T)\n",
    "\n",
    "# B_val = np.ones_like(B_val)\n",
    "\n",
    "zero_mask_val = X_class_val[:,:d] == 0\n",
    "B_val[zero_mask_val] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero_val = np.sum(B_val, axis=1) != 0\n",
    "B_val = B_val[mask_nonzero_val]\n",
    "X_class_val = X_class_val[mask_nonzero_val]\n",
    "Y_class_val = Y_class_val[mask_nonzero_val]\n",
    "\n",
    "X_class_teacher_val = X_class_teacher_val[mask_nonzero_val]\n",
    "Y_class_teacher_val = Y_class_teacher_val[mask_nonzero_val]\n",
    "\n",
    "X_class_val[:,:d] = X_class_val[:,:d] * B_val\n",
    "X_class_val.shape, Y_class_val.shape, B_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4828, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 87/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2058 - loss: 1.2979 - prc: 0.3598 - roc_auc: 0.5588\n",
      "Epoch 1: val_roc_auc improved from -inf to 0.65913, saving model to /work/users/d/d/ddinh/aaco/src/best_teacher_model.keras\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2435 - loss: 1.2549 - prc: 0.3647 - roc_auc: 0.5697 - val_accuracy: 0.5083 - val_loss: 1.0657 - val_prc: 0.4660 - val_roc_auc: 0.6591\n",
      "Epoch 2/100\n",
      "\u001b[1m 99/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5750 - loss: 0.9012 - prc: 0.4558 - roc_auc: 0.6695\n",
      "Epoch 2: val_roc_auc improved from 0.65913 to 0.72066, saving model to /work/users/d/d/ddinh/aaco/src/best_teacher_model.keras\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.8932 - prc: 0.4572 - roc_auc: 0.6707 - val_accuracy: 0.4979 - val_loss: 1.0107 - val_prc: 0.5499 - val_roc_auc: 0.7207\n",
      "Epoch 3/100\n",
      "\u001b[1m105/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.6105 - loss: 0.8053 - prc: 0.5101 - roc_auc: 0.7010\n",
      "Epoch 3: val_roc_auc improved from 0.72066 to 0.73657, saving model to /work/users/d/d/ddinh/aaco/src/best_teacher_model.keras\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6107 - loss: 0.8033 - prc: 0.5098 - roc_auc: 0.7019 - val_accuracy: 0.5104 - val_loss: 0.9871 - val_prc: 0.5706 - val_roc_auc: 0.7366\n",
      "Epoch 4/100\n",
      "\u001b[1m 98/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6051 - loss: 0.7769 - prc: 0.5049 - roc_auc: 0.7115\n",
      "Epoch 4: val_roc_auc improved from 0.73657 to 0.74227, saving model to /work/users/d/d/ddinh/aaco/src/best_teacher_model.keras\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 0.7754 - prc: 0.5086 - roc_auc: 0.7134 - val_accuracy: 0.5538 - val_loss: 0.9713 - val_prc: 0.5816 - val_roc_auc: 0.7423\n",
      "Epoch 5/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.6063 - loss: 0.7682 - prc: 0.5470 - roc_auc: 0.7300\n",
      "Epoch 5: val_roc_auc improved from 0.74227 to 0.74460, saving model to /work/users/d/d/ddinh/aaco/src/best_teacher_model.keras\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.7667 - prc: 0.5448 - roc_auc: 0.7296 - val_accuracy: 0.5642 - val_loss: 0.9371 - val_prc: 0.5866 - val_roc_auc: 0.7446\n",
      "Epoch 6/100\n",
      "\u001b[1m113/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.6211 - loss: 0.7557 - prc: 0.5455 - roc_auc: 0.7337\n",
      "Epoch 6: val_roc_auc improved from 0.74460 to 0.74511, saving model to /work/users/d/d/ddinh/aaco/src/best_teacher_model.keras\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6207 - loss: 0.7555 - prc: 0.5450 - roc_auc: 0.7337 - val_accuracy: 0.5642 - val_loss: 0.9407 - val_prc: 0.5895 - val_roc_auc: 0.7451\n",
      "Epoch 7/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.6126 - loss: 0.7454 - prc: 0.5634 - roc_auc: 0.7471\n",
      "Epoch 7: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.7455 - prc: 0.5607 - roc_auc: 0.7459 - val_accuracy: 0.5611 - val_loss: 0.9166 - val_prc: 0.5887 - val_roc_auc: 0.7435\n",
      "Epoch 8/100\n",
      "\u001b[1m 86/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6221 - loss: 0.7421 - prc: 0.5519 - roc_auc: 0.7419\n",
      "Epoch 8: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6196 - loss: 0.7427 - prc: 0.5501 - roc_auc: 0.7418 - val_accuracy: 0.5766 - val_loss: 0.9018 - val_prc: 0.5861 - val_roc_auc: 0.7421\n",
      "Epoch 9/100\n",
      "\u001b[1m 99/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6125 - loss: 0.7397 - prc: 0.5552 - roc_auc: 0.7497\n",
      "Epoch 9: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.7398 - prc: 0.5532 - roc_auc: 0.7481 - val_accuracy: 0.5787 - val_loss: 0.9020 - val_prc: 0.5865 - val_roc_auc: 0.7427\n",
      "Epoch 10/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6262 - loss: 0.7327 - prc: 0.5554 - roc_auc: 0.7511\n",
      "Epoch 10: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6248 - loss: 0.7330 - prc: 0.5555 - roc_auc: 0.7505 - val_accuracy: 0.5776 - val_loss: 0.8901 - val_prc: 0.5828 - val_roc_auc: 0.7403\n",
      "Epoch 11/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6249 - loss: 0.7211 - prc: 0.5701 - roc_auc: 0.7652\n",
      "Epoch 11: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 0.7234 - prc: 0.5684 - roc_auc: 0.7625 - val_accuracy: 0.5538 - val_loss: 0.9008 - val_prc: 0.5806 - val_roc_auc: 0.7401\n",
      "Epoch 12/100\n",
      "\u001b[1m 98/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6303 - loss: 0.7309 - prc: 0.5780 - roc_auc: 0.7566\n",
      "Epoch 12: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6290 - loss: 0.7309 - prc: 0.5748 - roc_auc: 0.7556 - val_accuracy: 0.5704 - val_loss: 0.8757 - val_prc: 0.5833 - val_roc_auc: 0.7408\n",
      "Epoch 13/100\n",
      "\u001b[1m 99/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6284 - loss: 0.7020 - prc: 0.5825 - roc_auc: 0.7632\n",
      "Epoch 13: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6285 - loss: 0.7063 - prc: 0.5788 - roc_auc: 0.7615 - val_accuracy: 0.5663 - val_loss: 0.8752 - val_prc: 0.5709 - val_roc_auc: 0.7354\n",
      "Epoch 14/100\n",
      "\u001b[1m108/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.6169 - loss: 0.7201 - prc: 0.5619 - roc_auc: 0.7557\n",
      "Epoch 14: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6173 - loss: 0.7207 - prc: 0.5628 - roc_auc: 0.7558 - val_accuracy: 0.5580 - val_loss: 0.8644 - val_prc: 0.5829 - val_roc_auc: 0.7383\n",
      "Epoch 15/100\n",
      "\u001b[1m106/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.6370 - loss: 0.7293 - prc: 0.5837 - roc_auc: 0.7629\n",
      "Epoch 15: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 0.7286 - prc: 0.5818 - roc_auc: 0.7620 - val_accuracy: 0.5507 - val_loss: 0.8819 - val_prc: 0.5773 - val_roc_auc: 0.7381\n",
      "Epoch 16/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.6378 - loss: 0.7145 - prc: 0.5896 - roc_auc: 0.7633\n",
      "Epoch 16: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6364 - loss: 0.7157 - prc: 0.5874 - roc_auc: 0.7625 - val_accuracy: 0.5600 - val_loss: 0.8647 - val_prc: 0.5724 - val_roc_auc: 0.7376\n",
      "Epoch 17/100\n",
      "\u001b[1m106/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.6312 - loss: 0.7224 - prc: 0.5700 - roc_auc: 0.7562\n",
      "Epoch 17: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6306 - loss: 0.7221 - prc: 0.5712 - roc_auc: 0.7569 - val_accuracy: 0.5538 - val_loss: 0.8770 - val_prc: 0.5747 - val_roc_auc: 0.7389\n",
      "Epoch 18/100\n",
      "\u001b[1m106/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6262 - loss: 0.7089 - prc: 0.6003 - roc_auc: 0.7712\n",
      "Epoch 18: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6263 - loss: 0.7099 - prc: 0.5972 - roc_auc: 0.7698 - val_accuracy: 0.5611 - val_loss: 0.8548 - val_prc: 0.5777 - val_roc_auc: 0.7387\n",
      "Epoch 19/100\n",
      "\u001b[1m111/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.6309 - loss: 0.7165 - prc: 0.5850 - roc_auc: 0.7609\n",
      "Epoch 19: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6308 - loss: 0.7163 - prc: 0.5850 - roc_auc: 0.7612 - val_accuracy: 0.5497 - val_loss: 0.8687 - val_prc: 0.5706 - val_roc_auc: 0.7384\n",
      "Epoch 20/100\n",
      "\u001b[1m110/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.6356 - loss: 0.7066 - prc: 0.5766 - roc_auc: 0.7614\n",
      "Epoch 20: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 0.7075 - prc: 0.5774 - roc_auc: 0.7616 - val_accuracy: 0.5590 - val_loss: 0.8437 - val_prc: 0.5832 - val_roc_auc: 0.7420\n",
      "Epoch 21/100\n",
      "\u001b[1m102/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.6303 - loss: 0.7084 - prc: 0.5919 - roc_auc: 0.7653\n",
      "Epoch 21: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 0.7094 - prc: 0.5909 - roc_auc: 0.7652 - val_accuracy: 0.5342 - val_loss: 0.8567 - val_prc: 0.5737 - val_roc_auc: 0.7364\n",
      "Epoch 22/100\n",
      "\u001b[1m102/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6229 - loss: 0.7100 - prc: 0.5997 - roc_auc: 0.7716\n",
      "Epoch 22: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6229 - loss: 0.7107 - prc: 0.5975 - roc_auc: 0.7703 - val_accuracy: 0.5404 - val_loss: 0.8489 - val_prc: 0.5788 - val_roc_auc: 0.7398\n",
      "Epoch 23/100\n",
      "\u001b[1m102/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.6288 - loss: 0.7121 - prc: 0.5707 - roc_auc: 0.7593\n",
      "Epoch 23: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6290 - loss: 0.7120 - prc: 0.5736 - roc_auc: 0.7604 - val_accuracy: 0.5373 - val_loss: 0.8617 - val_prc: 0.5788 - val_roc_auc: 0.7418\n",
      "Epoch 24/100\n",
      "\u001b[1m105/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.6234 - loss: 0.7147 - prc: 0.5875 - roc_auc: 0.7663\n",
      "Epoch 24: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.7144 - prc: 0.5876 - roc_auc: 0.7661 - val_accuracy: 0.5373 - val_loss: 0.8600 - val_prc: 0.5782 - val_roc_auc: 0.7409\n",
      "Epoch 25/100\n",
      "\u001b[1m108/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6150 - loss: 0.7129 - prc: 0.5839 - roc_auc: 0.7640\n",
      "Epoch 25: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6161 - loss: 0.7125 - prc: 0.5846 - roc_auc: 0.7644 - val_accuracy: 0.5404 - val_loss: 0.8619 - val_prc: 0.5824 - val_roc_auc: 0.7437\n",
      "Epoch 26/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6301 - loss: 0.6931 - prc: 0.6109 - roc_auc: 0.7856\n",
      "Epoch 26: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6298 - loss: 0.6963 - prc: 0.6072 - roc_auc: 0.7826 - val_accuracy: 0.5435 - val_loss: 0.8652 - val_prc: 0.5825 - val_roc_auc: 0.7435\n",
      "Epoch 27/100\n",
      "\u001b[1m102/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.6331 - loss: 0.7115 - prc: 0.5819 - roc_auc: 0.7639\n",
      "Epoch 27: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6330 - loss: 0.7111 - prc: 0.5839 - roc_auc: 0.7646 - val_accuracy: 0.5497 - val_loss: 0.8458 - val_prc: 0.5796 - val_roc_auc: 0.7401\n",
      "Epoch 28/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.6397 - loss: 0.7023 - prc: 0.5946 - roc_auc: 0.7742\n",
      "Epoch 28: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6381 - loss: 0.7031 - prc: 0.5942 - roc_auc: 0.7736 - val_accuracy: 0.5362 - val_loss: 0.8630 - val_prc: 0.5768 - val_roc_auc: 0.7394\n",
      "Epoch 29/100\n",
      "\u001b[1m 98/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6225 - loss: 0.7127 - prc: 0.5652 - roc_auc: 0.7595\n",
      "Epoch 29: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 0.7111 - prc: 0.5702 - roc_auc: 0.7618 - val_accuracy: 0.5487 - val_loss: 0.8509 - val_prc: 0.5799 - val_roc_auc: 0.7408\n",
      "Epoch 30/100\n",
      "\u001b[1m106/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6370 - loss: 0.6935 - prc: 0.6009 - roc_auc: 0.7775\n",
      "Epoch 30: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6356 - loss: 0.6954 - prc: 0.6004 - roc_auc: 0.7766 - val_accuracy: 0.5466 - val_loss: 0.8473 - val_prc: 0.5866 - val_roc_auc: 0.7444\n",
      "Epoch 31/100\n",
      "\u001b[1m110/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.6288 - loss: 0.7122 - prc: 0.5915 - roc_auc: 0.7689\n",
      "Epoch 31: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6289 - loss: 0.7116 - prc: 0.5921 - roc_auc: 0.7692 - val_accuracy: 0.5538 - val_loss: 0.8456 - val_prc: 0.5855 - val_roc_auc: 0.7437\n",
      "Epoch 32/100\n",
      "\u001b[1m112/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.6364 - loss: 0.7044 - prc: 0.6087 - roc_auc: 0.7765\n",
      "Epoch 32: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6362 - loss: 0.7045 - prc: 0.6077 - roc_auc: 0.7761 - val_accuracy: 0.5342 - val_loss: 0.8624 - val_prc: 0.5758 - val_roc_auc: 0.7401\n",
      "Epoch 33/100\n",
      "\u001b[1m110/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.6320 - loss: 0.7060 - prc: 0.6184 - roc_auc: 0.7800\n",
      "Epoch 33: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6318 - loss: 0.7059 - prc: 0.6163 - roc_auc: 0.7793 - val_accuracy: 0.5300 - val_loss: 0.8659 - val_prc: 0.5713 - val_roc_auc: 0.7374\n",
      "Epoch 34/100\n",
      "\u001b[1m113/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.6300 - loss: 0.7057 - prc: 0.6033 - roc_auc: 0.7787\n",
      "Epoch 34: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6301 - loss: 0.7055 - prc: 0.6031 - roc_auc: 0.7785 - val_accuracy: 0.5497 - val_loss: 0.8502 - val_prc: 0.5755 - val_roc_auc: 0.7389\n",
      "Epoch 35/100\n",
      "\u001b[1m112/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.6534 - loss: 0.6918 - prc: 0.6247 - roc_auc: 0.7849\n",
      "Epoch 35: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6516 - loss: 0.6928 - prc: 0.6226 - roc_auc: 0.7841 - val_accuracy: 0.5373 - val_loss: 0.8616 - val_prc: 0.5750 - val_roc_auc: 0.7405\n",
      "Epoch 36/100\n",
      "\u001b[1m109/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.6367 - loss: 0.6925 - prc: 0.6161 - roc_auc: 0.7842\n",
      "Epoch 36: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6362 - loss: 0.6936 - prc: 0.6145 - roc_auc: 0.7832 - val_accuracy: 0.5321 - val_loss: 0.8675 - val_prc: 0.5750 - val_roc_auc: 0.7393\n",
      "Epoch 37/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.6270 - loss: 0.6922 - prc: 0.6170 - roc_auc: 0.7840\n",
      "Epoch 37: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6286 - loss: 0.6934 - prc: 0.6148 - roc_auc: 0.7828 - val_accuracy: 0.5280 - val_loss: 0.8619 - val_prc: 0.5758 - val_roc_auc: 0.7383\n",
      "Epoch 38/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.6344 - loss: 0.7055 - prc: 0.6153 - roc_auc: 0.7774\n",
      "Epoch 38: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6344 - loss: 0.7047 - prc: 0.6139 - roc_auc: 0.7775 - val_accuracy: 0.5393 - val_loss: 0.8591 - val_prc: 0.5770 - val_roc_auc: 0.7416\n",
      "Epoch 39/100\n",
      "\u001b[1m110/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.6363 - loss: 0.7011 - prc: 0.6021 - roc_auc: 0.7776\n",
      "Epoch 39: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6361 - loss: 0.7011 - prc: 0.6022 - roc_auc: 0.7774 - val_accuracy: 0.5321 - val_loss: 0.8705 - val_prc: 0.5745 - val_roc_auc: 0.7386\n",
      "Epoch 40/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.6437 - loss: 0.7022 - prc: 0.6006 - roc_auc: 0.7705\n",
      "Epoch 40: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6435 - loss: 0.7018 - prc: 0.6011 - roc_auc: 0.7713 - val_accuracy: 0.5300 - val_loss: 0.8613 - val_prc: 0.5795 - val_roc_auc: 0.7422\n",
      "Epoch 41/100\n",
      "\u001b[1m107/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6524 - loss: 0.6934 - prc: 0.6147 - roc_auc: 0.7799\n",
      "Epoch 41: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6510 - loss: 0.6940 - prc: 0.6136 - roc_auc: 0.7797 - val_accuracy: 0.5455 - val_loss: 0.8631 - val_prc: 0.5733 - val_roc_auc: 0.7372\n",
      "Epoch 42/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6348 - loss: 0.7020 - prc: 0.6096 - roc_auc: 0.7781\n",
      "Epoch 42: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 0.7014 - prc: 0.6090 - roc_auc: 0.7781 - val_accuracy: 0.5518 - val_loss: 0.8521 - val_prc: 0.5793 - val_roc_auc: 0.7424\n",
      "Epoch 43/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6474 - loss: 0.6879 - prc: 0.6067 - roc_auc: 0.7780\n",
      "Epoch 43: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6450 - loss: 0.6896 - prc: 0.6066 - roc_auc: 0.7782 - val_accuracy: 0.5497 - val_loss: 0.8636 - val_prc: 0.5751 - val_roc_auc: 0.7376\n",
      "Epoch 44/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6462 - loss: 0.6808 - prc: 0.6123 - roc_auc: 0.7898\n",
      "Epoch 44: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6450 - loss: 0.6833 - prc: 0.6125 - roc_auc: 0.7886 - val_accuracy: 0.5424 - val_loss: 0.8594 - val_prc: 0.5692 - val_roc_auc: 0.7374\n",
      "Epoch 45/100\n",
      "\u001b[1m105/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.6314 - loss: 0.6831 - prc: 0.6123 - roc_auc: 0.7855\n",
      "Epoch 45: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6316 - loss: 0.6848 - prc: 0.6117 - roc_auc: 0.7848 - val_accuracy: 0.5445 - val_loss: 0.8617 - val_prc: 0.5727 - val_roc_auc: 0.7376\n",
      "Epoch 46/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.6496 - loss: 0.6717 - prc: 0.6152 - roc_auc: 0.7890\n",
      "Epoch 46: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6483 - loss: 0.6753 - prc: 0.6146 - roc_auc: 0.7875 - val_accuracy: 0.5404 - val_loss: 0.8601 - val_prc: 0.5689 - val_roc_auc: 0.7377\n",
      "Epoch 47/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6491 - loss: 0.6933 - prc: 0.6258 - roc_auc: 0.7848  \n",
      "Epoch 47: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6476 - loss: 0.6938 - prc: 0.6230 - roc_auc: 0.7840 - val_accuracy: 0.5321 - val_loss: 0.8747 - val_prc: 0.5728 - val_roc_auc: 0.7409\n",
      "Epoch 48/100\n",
      "\u001b[1m109/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.6443 - loss: 0.6887 - prc: 0.6197 - roc_auc: 0.7823\n",
      "Epoch 48: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6440 - loss: 0.6892 - prc: 0.6191 - roc_auc: 0.7823 - val_accuracy: 0.5352 - val_loss: 0.8719 - val_prc: 0.5698 - val_roc_auc: 0.7391\n",
      "Epoch 49/100\n",
      "\u001b[1m113/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6323 - loss: 0.6963 - prc: 0.6070 - roc_auc: 0.7800\n",
      "Epoch 49: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6329 - loss: 0.6961 - prc: 0.6074 - roc_auc: 0.7801 - val_accuracy: 0.5538 - val_loss: 0.8573 - val_prc: 0.5785 - val_roc_auc: 0.7420\n",
      "Epoch 50/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6592 - loss: 0.6909 - prc: 0.6107 - roc_auc: 0.7764\n",
      "Epoch 50: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6559 - loss: 0.6912 - prc: 0.6105 - roc_auc: 0.7774 - val_accuracy: 0.5414 - val_loss: 0.8642 - val_prc: 0.5773 - val_roc_auc: 0.7403\n",
      "Epoch 51/100\n",
      "\u001b[1m 99/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6457 - loss: 0.6847 - prc: 0.6367 - roc_auc: 0.7957\n",
      "Epoch 51: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6441 - loss: 0.6863 - prc: 0.6324 - roc_auc: 0.7932 - val_accuracy: 0.5507 - val_loss: 0.8583 - val_prc: 0.5746 - val_roc_auc: 0.7405\n",
      "Epoch 52/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6553 - loss: 0.6774 - prc: 0.6205 - roc_auc: 0.7826\n",
      "Epoch 52: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6528 - loss: 0.6796 - prc: 0.6200 - roc_auc: 0.7831 - val_accuracy: 0.5580 - val_loss: 0.8606 - val_prc: 0.5778 - val_roc_auc: 0.7402\n",
      "Epoch 53/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6448 - loss: 0.6955 - prc: 0.6311 - roc_auc: 0.7847\n",
      "Epoch 53: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6440 - loss: 0.6944 - prc: 0.6284 - roc_auc: 0.7843 - val_accuracy: 0.5497 - val_loss: 0.8605 - val_prc: 0.5762 - val_roc_auc: 0.7388\n",
      "Epoch 54/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.6512 - loss: 0.6865 - prc: 0.6372 - roc_auc: 0.7928\n",
      "Epoch 54: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6505 - loss: 0.6871 - prc: 0.6344 - roc_auc: 0.7915 - val_accuracy: 0.5466 - val_loss: 0.8760 - val_prc: 0.5730 - val_roc_auc: 0.7396\n",
      "Epoch 55/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.6358 - loss: 0.7017 - prc: 0.6196 - roc_auc: 0.7817\n",
      "Epoch 55: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 0.6999 - prc: 0.6201 - roc_auc: 0.7825 - val_accuracy: 0.5487 - val_loss: 0.8678 - val_prc: 0.5796 - val_roc_auc: 0.7446\n",
      "Epoch 56/100\n",
      "\u001b[1m110/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.6408 - loss: 0.6975 - prc: 0.6351 - roc_auc: 0.7872\n",
      "Epoch 56: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6414 - loss: 0.6965 - prc: 0.6335 - roc_auc: 0.7871 - val_accuracy: 0.5404 - val_loss: 0.8789 - val_prc: 0.5715 - val_roc_auc: 0.7373\n",
      "Epoch 57/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.6445 - loss: 0.6796 - prc: 0.6188 - roc_auc: 0.7854\n",
      "Epoch 57: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6437 - loss: 0.6810 - prc: 0.6192 - roc_auc: 0.7857 - val_accuracy: 0.5393 - val_loss: 0.8693 - val_prc: 0.5717 - val_roc_auc: 0.7381\n",
      "Epoch 58/100\n",
      "\u001b[1m107/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.6483 - loss: 0.6728 - prc: 0.6291 - roc_auc: 0.7925\n",
      "Epoch 58: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6474 - loss: 0.6749 - prc: 0.6279 - roc_auc: 0.7917 - val_accuracy: 0.5518 - val_loss: 0.8653 - val_prc: 0.5807 - val_roc_auc: 0.7429\n",
      "Epoch 59/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.6539 - loss: 0.6873 - prc: 0.6427 - roc_auc: 0.7946\n",
      "Epoch 59: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6531 - loss: 0.6871 - prc: 0.6397 - roc_auc: 0.7937 - val_accuracy: 0.5383 - val_loss: 0.8718 - val_prc: 0.5735 - val_roc_auc: 0.7384\n",
      "Epoch 60/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6565 - loss: 0.6712 - prc: 0.6486 - roc_auc: 0.8023\n",
      "Epoch 60: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6545 - loss: 0.6734 - prc: 0.6446 - roc_auc: 0.8001 - val_accuracy: 0.5559 - val_loss: 0.8635 - val_prc: 0.5785 - val_roc_auc: 0.7417\n",
      "Epoch 61/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6418 - loss: 0.6788 - prc: 0.6269 - roc_auc: 0.7929  \n",
      "Epoch 61: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6421 - loss: 0.6803 - prc: 0.6264 - roc_auc: 0.7921 - val_accuracy: 0.5424 - val_loss: 0.8762 - val_prc: 0.5738 - val_roc_auc: 0.7388\n",
      "Epoch 62/100\n",
      "\u001b[1m110/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.6470 - loss: 0.6790 - prc: 0.6306 - roc_auc: 0.7993\n",
      "Epoch 62: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6474 - loss: 0.6794 - prc: 0.6301 - roc_auc: 0.7984 - val_accuracy: 0.5497 - val_loss: 0.8679 - val_prc: 0.5737 - val_roc_auc: 0.7387\n",
      "Epoch 63/100\n",
      "\u001b[1m113/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.6464 - loss: 0.6863 - prc: 0.6142 - roc_auc: 0.7834\n",
      "Epoch 63: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6462 - loss: 0.6862 - prc: 0.6148 - roc_auc: 0.7838 - val_accuracy: 0.5528 - val_loss: 0.8694 - val_prc: 0.5709 - val_roc_auc: 0.7384\n",
      "Epoch 64/100\n",
      "\u001b[1m 97/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6406 - loss: 0.6772 - prc: 0.6343 - roc_auc: 0.7972\n",
      "Epoch 64: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6409 - loss: 0.6792 - prc: 0.6326 - roc_auc: 0.7955 - val_accuracy: 0.5466 - val_loss: 0.8707 - val_prc: 0.5742 - val_roc_auc: 0.7392\n",
      "Epoch 65/100\n",
      "\u001b[1m112/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.6556 - loss: 0.6908 - prc: 0.6143 - roc_auc: 0.7855\n",
      "Epoch 65: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 0.6902 - prc: 0.6154 - roc_auc: 0.7859 - val_accuracy: 0.5404 - val_loss: 0.8817 - val_prc: 0.5698 - val_roc_auc: 0.7369\n",
      "Epoch 66/100\n",
      "\u001b[1m103/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.6692 - loss: 0.6599 - prc: 0.6534 - roc_auc: 0.8048\n",
      "Epoch 66: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6663 - loss: 0.6635 - prc: 0.6496 - roc_auc: 0.8027 - val_accuracy: 0.5507 - val_loss: 0.8679 - val_prc: 0.5758 - val_roc_auc: 0.7403\n",
      "Epoch 67/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6600 - loss: 0.6650 - prc: 0.6425 - roc_auc: 0.7993\n",
      "Epoch 67: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6582 - loss: 0.6676 - prc: 0.6408 - roc_auc: 0.7980 - val_accuracy: 0.5455 - val_loss: 0.8769 - val_prc: 0.5737 - val_roc_auc: 0.7411\n",
      "Epoch 68/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6577 - loss: 0.6630 - prc: 0.6384 - roc_auc: 0.8031\n",
      "Epoch 68: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6559 - loss: 0.6662 - prc: 0.6366 - roc_auc: 0.8011 - val_accuracy: 0.5569 - val_loss: 0.8707 - val_prc: 0.5688 - val_roc_auc: 0.7375\n",
      "Epoch 69/100\n",
      "\u001b[1m 98/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6334 - loss: 0.6935 - prc: 0.6348 - roc_auc: 0.7936\n",
      "Epoch 69: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6361 - loss: 0.6913 - prc: 0.6337 - roc_auc: 0.7933 - val_accuracy: 0.5445 - val_loss: 0.8853 - val_prc: 0.5734 - val_roc_auc: 0.7401\n",
      "Epoch 70/100\n",
      "\u001b[1m 98/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6505 - loss: 0.6739 - prc: 0.6253 - roc_auc: 0.7936\n",
      "Epoch 70: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6506 - loss: 0.6751 - prc: 0.6265 - roc_auc: 0.7934 - val_accuracy: 0.5528 - val_loss: 0.8874 - val_prc: 0.5767 - val_roc_auc: 0.7407\n",
      "Epoch 71/100\n",
      "\u001b[1m102/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6645 - loss: 0.6690 - prc: 0.6356 - roc_auc: 0.7899\n",
      "Epoch 71: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6628 - loss: 0.6709 - prc: 0.6353 - roc_auc: 0.7905 - val_accuracy: 0.5518 - val_loss: 0.8779 - val_prc: 0.5725 - val_roc_auc: 0.7375\n",
      "Epoch 72/100\n",
      "\u001b[1m105/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.6415 - loss: 0.6933 - prc: 0.6199 - roc_auc: 0.7820\n",
      "Epoch 72: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6435 - loss: 0.6911 - prc: 0.6221 - roc_auc: 0.7838 - val_accuracy: 0.5476 - val_loss: 0.8813 - val_prc: 0.5801 - val_roc_auc: 0.7404\n",
      "Epoch 73/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6604 - loss: 0.6878 - prc: 0.6400 - roc_auc: 0.7884\n",
      "Epoch 73: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6596 - loss: 0.6864 - prc: 0.6391 - roc_auc: 0.7892 - val_accuracy: 0.5528 - val_loss: 0.8892 - val_prc: 0.5693 - val_roc_auc: 0.7382\n",
      "Epoch 74/100\n",
      "\u001b[1m106/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.6456 - loss: 0.6942 - prc: 0.6131 - roc_auc: 0.7831\n",
      "Epoch 74: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6472 - loss: 0.6922 - prc: 0.6160 - roc_auc: 0.7846 - val_accuracy: 0.5466 - val_loss: 0.8817 - val_prc: 0.5782 - val_roc_auc: 0.7407\n",
      "Epoch 75/100\n",
      "\u001b[1m112/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6539 - loss: 0.6732 - prc: 0.6446 - roc_auc: 0.7983\n",
      "Epoch 75: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6540 - loss: 0.6736 - prc: 0.6437 - roc_auc: 0.7980 - val_accuracy: 0.5600 - val_loss: 0.8727 - val_prc: 0.5800 - val_roc_auc: 0.7440\n",
      "Epoch 76/100\n",
      "\u001b[1m111/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.6612 - loss: 0.6658 - prc: 0.6405 - roc_auc: 0.7993\n",
      "Epoch 76: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 0.6669 - prc: 0.6399 - roc_auc: 0.7989 - val_accuracy: 0.5497 - val_loss: 0.8896 - val_prc: 0.5690 - val_roc_auc: 0.7348\n",
      "Epoch 77/100\n",
      "\u001b[1m105/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6616 - loss: 0.6695 - prc: 0.6421 - roc_auc: 0.7987\n",
      "Epoch 77: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6603 - loss: 0.6703 - prc: 0.6408 - roc_auc: 0.7981 - val_accuracy: 0.5497 - val_loss: 0.8833 - val_prc: 0.5743 - val_roc_auc: 0.7392\n",
      "Epoch 78/100\n",
      "\u001b[1m 95/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6575 - loss: 0.6660 - prc: 0.6451 - roc_auc: 0.8003\n",
      "Epoch 78: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6563 - loss: 0.6683 - prc: 0.6428 - roc_auc: 0.7992 - val_accuracy: 0.5559 - val_loss: 0.8825 - val_prc: 0.5706 - val_roc_auc: 0.7382\n",
      "Epoch 79/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.6564 - loss: 0.6726 - prc: 0.6389 - roc_auc: 0.7985\n",
      "Epoch 79: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6560 - loss: 0.6730 - prc: 0.6390 - roc_auc: 0.7982 - val_accuracy: 0.5455 - val_loss: 0.8918 - val_prc: 0.5731 - val_roc_auc: 0.7381\n",
      "Epoch 80/100\n",
      "\u001b[1m 97/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6538 - loss: 0.6750 - prc: 0.6360 - roc_auc: 0.7958\n",
      "Epoch 80: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 0.6747 - prc: 0.6363 - roc_auc: 0.7960 - val_accuracy: 0.5393 - val_loss: 0.9004 - val_prc: 0.5717 - val_roc_auc: 0.7353\n",
      "Epoch 81/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6550 - loss: 0.6796 - prc: 0.6214 - roc_auc: 0.7878\n",
      "Epoch 81: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 0.6789 - prc: 0.6244 - roc_auc: 0.7893 - val_accuracy: 0.5435 - val_loss: 0.8934 - val_prc: 0.5670 - val_roc_auc: 0.7343\n",
      "Epoch 82/100\n",
      "\u001b[1m107/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.6575 - loss: 0.6700 - prc: 0.6372 - roc_auc: 0.7995\n",
      "Epoch 82: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6570 - loss: 0.6708 - prc: 0.6373 - roc_auc: 0.7991 - val_accuracy: 0.5487 - val_loss: 0.8881 - val_prc: 0.5725 - val_roc_auc: 0.7391\n",
      "Epoch 83/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6541 - loss: 0.6683 - prc: 0.6667 - roc_auc: 0.8068\n",
      "Epoch 83: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6541 - loss: 0.6697 - prc: 0.6616 - roc_auc: 0.8048 - val_accuracy: 0.5528 - val_loss: 0.8969 - val_prc: 0.5666 - val_roc_auc: 0.7379\n",
      "Epoch 84/100\n",
      "\u001b[1m102/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.6584 - loss: 0.6807 - prc: 0.6396 - roc_auc: 0.7966\n",
      "Epoch 84: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6583 - loss: 0.6799 - prc: 0.6392 - roc_auc: 0.7964 - val_accuracy: 0.5497 - val_loss: 0.8850 - val_prc: 0.5674 - val_roc_auc: 0.7372\n",
      "Epoch 85/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6468 - loss: 0.6780 - prc: 0.6419 - roc_auc: 0.7934\n",
      "Epoch 85: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6484 - loss: 0.6773 - prc: 0.6422 - roc_auc: 0.7943 - val_accuracy: 0.5507 - val_loss: 0.8865 - val_prc: 0.5663 - val_roc_auc: 0.7367\n",
      "Epoch 86/100\n",
      "\u001b[1m107/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.6535 - loss: 0.6645 - prc: 0.6560 - roc_auc: 0.8044\n",
      "Epoch 86: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6535 - loss: 0.6658 - prc: 0.6540 - roc_auc: 0.8034 - val_accuracy: 0.5445 - val_loss: 0.8883 - val_prc: 0.5682 - val_roc_auc: 0.7368\n",
      "Epoch 87/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6562 - loss: 0.6848 - prc: 0.6468 - roc_auc: 0.7972\n",
      "Epoch 87: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 0.6827 - prc: 0.6463 - roc_auc: 0.7976 - val_accuracy: 0.5549 - val_loss: 0.8855 - val_prc: 0.5715 - val_roc_auc: 0.7398\n",
      "Epoch 88/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6757 - loss: 0.6579 - prc: 0.6533 - roc_auc: 0.8075\n",
      "Epoch 88: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6734 - loss: 0.6598 - prc: 0.6519 - roc_auc: 0.8063 - val_accuracy: 0.5300 - val_loss: 0.9078 - val_prc: 0.5603 - val_roc_auc: 0.7306\n",
      "Epoch 89/100\n",
      "\u001b[1m105/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6482 - loss: 0.6845 - prc: 0.6387 - roc_auc: 0.7953\n",
      "Epoch 89: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6488 - loss: 0.6829 - prc: 0.6386 - roc_auc: 0.7956 - val_accuracy: 0.5455 - val_loss: 0.8985 - val_prc: 0.5660 - val_roc_auc: 0.7368\n",
      "Epoch 90/100\n",
      "\u001b[1m105/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.6580 - loss: 0.6819 - prc: 0.6375 - roc_auc: 0.7951\n",
      "Epoch 90: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6579 - loss: 0.6805 - prc: 0.6377 - roc_auc: 0.7954 - val_accuracy: 0.5445 - val_loss: 0.8963 - val_prc: 0.5665 - val_roc_auc: 0.7352\n",
      "Epoch 91/100\n",
      "\u001b[1m102/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6569 - loss: 0.6726 - prc: 0.6474 - roc_auc: 0.7986   \n",
      "Epoch 91: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6568 - loss: 0.6726 - prc: 0.6464 - roc_auc: 0.7984 - val_accuracy: 0.5487 - val_loss: 0.8998 - val_prc: 0.5713 - val_roc_auc: 0.7388\n",
      "Epoch 92/100\n",
      "\u001b[1m100/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6602 - loss: 0.6729 - prc: 0.6340 - roc_auc: 0.7968\n",
      "Epoch 92: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6583 - loss: 0.6735 - prc: 0.6345 - roc_auc: 0.7964 - val_accuracy: 0.5424 - val_loss: 0.8952 - val_prc: 0.5674 - val_roc_auc: 0.7363\n",
      "Epoch 93/100\n",
      "\u001b[1m 99/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6573 - loss: 0.6670 - prc: 0.6609 - roc_auc: 0.8130\n",
      "Epoch 93: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6572 - loss: 0.6670 - prc: 0.6584 - roc_auc: 0.8110 - val_accuracy: 0.5435 - val_loss: 0.8903 - val_prc: 0.5678 - val_roc_auc: 0.7387\n",
      "Epoch 94/100\n",
      "\u001b[1m111/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.6669 - loss: 0.6540 - prc: 0.6540 - roc_auc: 0.8091\n",
      "Epoch 94: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.6553 - prc: 0.6531 - roc_auc: 0.8083 - val_accuracy: 0.5455 - val_loss: 0.8877 - val_prc: 0.5677 - val_roc_auc: 0.7394\n",
      "Epoch 95/100\n",
      "\u001b[1m101/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6618 - loss: 0.6758 - prc: 0.6388 - roc_auc: 0.7985\n",
      "Epoch 95: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6614 - loss: 0.6751 - prc: 0.6391 - roc_auc: 0.7985 - val_accuracy: 0.5435 - val_loss: 0.9081 - val_prc: 0.5639 - val_roc_auc: 0.7329\n",
      "Epoch 96/100\n",
      "\u001b[1m 99/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6679 - loss: 0.6525 - prc: 0.6680 - roc_auc: 0.8101\n",
      "Epoch 96: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.6554 - prc: 0.6638 - roc_auc: 0.8083 - val_accuracy: 0.5497 - val_loss: 0.8944 - val_prc: 0.5686 - val_roc_auc: 0.7379\n",
      "Epoch 97/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.6566 - loss: 0.6623 - prc: 0.6577 - roc_auc: 0.8081\n",
      "Epoch 97: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6564 - loss: 0.6631 - prc: 0.6569 - roc_auc: 0.8074 - val_accuracy: 0.5507 - val_loss: 0.8961 - val_prc: 0.5691 - val_roc_auc: 0.7393\n",
      "Epoch 98/100\n",
      "\u001b[1m107/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.6713 - loss: 0.6577 - prc: 0.6540 - roc_auc: 0.8078\n",
      "Epoch 98: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 0.6589 - prc: 0.6534 - roc_auc: 0.8073 - val_accuracy: 0.5487 - val_loss: 0.8913 - val_prc: 0.5716 - val_roc_auc: 0.7412\n",
      "Epoch 99/100\n",
      "\u001b[1m107/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.6667 - loss: 0.6599 - prc: 0.6496 - roc_auc: 0.8051\n",
      "Epoch 99: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.6609 - prc: 0.6490 - roc_auc: 0.8044 - val_accuracy: 0.5383 - val_loss: 0.9144 - val_prc: 0.5698 - val_roc_auc: 0.7348\n",
      "Epoch 100/100\n",
      "\u001b[1m104/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.6451 - loss: 0.6712 - prc: 0.6479 - roc_auc: 0.7988\n",
      "Epoch 100: val_roc_auc did not improve from 0.74511\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6470 - loss: 0.6707 - prc: 0.6473 - roc_auc: 0.7991 - val_accuracy: 0.5538 - val_loss: 0.8989 - val_prc: 0.5731 - val_roc_auc: 0.7412\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "num_features = train_x_ts.shape[1]\n",
    "num_classes = 3\n",
    "\n",
    "def build_mlp(input_dim, output_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(output_dim, activation=\"softmax\")  \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "teacher_model = build_mlp(input_dim=num_features, output_dim=num_classes)\n",
    "teacher_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                      metrics=['accuracy', AUC(name='roc_auc', multi_label=True, num_labels=3), AUC(name='prc', curve='PR', multi_label=True, num_labels=3)])\n",
    "\n",
    "checkpoint = ModelCheckpoint('/work/users/d/d/ddinh/aaco/src/best_teacher_model.keras', monitor='val_roc_auc', save_best_only=True, mode='max', verbose=1)\n",
    "teacher_model.fit(train_x_ts, train_y_ts, epochs=100, batch_size=32, validation_split=0.2, callbacks=[checkpoint])\n",
    "teacher_model.load_weights('/work/users/d/d/ddinh/aaco/src/best_teacher_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.5904 - loss: 0.8710 - prc: 0.4852 - roc_auc: 0.6683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8982448577880859,\n",
       " 0.5717597007751465,\n",
       " 0.6643443703651428,\n",
       " 0.48588839173316956]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.evaluate(X_class_val, Y_class_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this with with using just a subset of featues. ensure that using all features make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Batch 1/35394, Loss: 0.5193\n",
      "Batch 626/35394, Loss: 0.3765\n",
      "Batch 1251/35394, Loss: 0.5077\n",
      "Batch 1876/35394, Loss: 0.4729\n",
      "Batch 2501/35394, Loss: 0.3358\n",
      "Batch 3126/35394, Loss: 0.4891\n",
      "Batch 3751/35394, Loss: 0.3676\n",
      "Batch 4376/35394, Loss: 0.3881\n",
      "Batch 5001/35394, Loss: 0.3793\n",
      "Batch 5626/35394, Loss: 0.3707\n",
      "Batch 6251/35394, Loss: 0.4357\n",
      "Batch 6876/35394, Loss: 0.3745\n",
      "Batch 7501/35394, Loss: 0.3332\n",
      "Batch 8126/35394, Loss: 0.3348\n",
      "Batch 8751/35394, Loss: 0.3708\n",
      "Batch 9376/35394, Loss: 0.4786\n",
      "Batch 10001/35394, Loss: 0.4089\n",
      "Batch 10626/35394, Loss: 0.3526\n",
      "Batch 11251/35394, Loss: 0.4234\n",
      "Batch 11876/35394, Loss: 0.3476\n",
      "Batch 12501/35394, Loss: 0.3420\n",
      "Batch 13126/35394, Loss: 0.3321\n",
      "Batch 13751/35394, Loss: 0.3300\n",
      "Batch 14376/35394, Loss: 0.3861\n",
      "Batch 15001/35394, Loss: 0.4030\n",
      "Batch 15626/35394, Loss: 0.4491\n",
      "Batch 16251/35394, Loss: 0.3918\n",
      "Batch 16876/35394, Loss: 0.4056\n",
      "Batch 17501/35394, Loss: 0.3621\n",
      "Batch 18126/35394, Loss: 0.3592\n",
      "Batch 18751/35394, Loss: 0.3321\n",
      "Batch 19376/35394, Loss: 0.4093\n",
      "Batch 20001/35394, Loss: 0.3418\n",
      "Batch 20626/35394, Loss: 0.3637\n",
      "Batch 21251/35394, Loss: 0.3948\n",
      "Batch 21876/35394, Loss: 0.3428\n",
      "Batch 22501/35394, Loss: 0.4179\n",
      "Batch 23126/35394, Loss: 0.4044\n",
      "Batch 23751/35394, Loss: 0.3322\n",
      "Batch 24376/35394, Loss: 0.3659\n",
      "Batch 25001/35394, Loss: 0.4075\n",
      "Batch 25626/35394, Loss: 0.4229\n",
      "Batch 26251/35394, Loss: 0.4141\n",
      "Batch 26876/35394, Loss: 0.3093\n",
      "Batch 27501/35394, Loss: 0.3118\n",
      "Batch 28126/35394, Loss: 0.3644\n",
      "Batch 28751/35394, Loss: 0.5149\n",
      "Batch 29376/35394, Loss: 0.3492\n",
      "Batch 30001/35394, Loss: 0.3546\n",
      "Batch 30626/35394, Loss: 0.3801\n",
      "Batch 31251/35394, Loss: 0.4180\n",
      "Batch 31876/35394, Loss: 0.3389\n",
      "Batch 32501/35394, Loss: 0.3762\n",
      "Batch 33126/35394, Loss: 0.3809\n",
      "Batch 33751/35394, Loss: 0.3618\n",
      "Batch 34376/35394, Loss: 0.3504\n",
      "Batch 35001/35394, Loss: 0.3654\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step\n",
      "Student Validation Accuracy: 0.5562\n",
      "Epoch 2/100\n",
      "Batch 1/35394, Loss: 0.3996\n",
      "Batch 626/35394, Loss: 0.3897\n",
      "Batch 1251/35394, Loss: 0.3567\n",
      "Batch 1876/35394, Loss: 0.4062\n",
      "Batch 2501/35394, Loss: 0.3269\n",
      "Batch 3126/35394, Loss: 0.3457\n",
      "Batch 3751/35394, Loss: 0.3933\n",
      "Batch 4376/35394, Loss: 0.4715\n",
      "Batch 5001/35394, Loss: 0.3360\n",
      "Batch 5626/35394, Loss: 0.3430\n",
      "Batch 6251/35394, Loss: 0.3448\n",
      "Batch 6876/35394, Loss: 0.3548\n",
      "Batch 7501/35394, Loss: 0.3606\n",
      "Batch 8126/35394, Loss: 0.3718\n",
      "Batch 8751/35394, Loss: 0.3589\n",
      "Batch 9376/35394, Loss: 0.3579\n",
      "Batch 10001/35394, Loss: 0.3417\n",
      "Batch 10626/35394, Loss: 0.4273\n",
      "Batch 11251/35394, Loss: 0.3886\n",
      "Batch 11876/35394, Loss: 0.3939\n",
      "Batch 12501/35394, Loss: 0.2912\n",
      "Batch 13126/35394, Loss: 0.4571\n",
      "Batch 13751/35394, Loss: 0.3369\n",
      "Batch 14376/35394, Loss: 0.3730\n",
      "Batch 15001/35394, Loss: 0.3746\n",
      "Batch 15626/35394, Loss: 0.4209\n",
      "Batch 16251/35394, Loss: 0.4140\n",
      "Batch 16876/35394, Loss: 0.3227\n",
      "Batch 17501/35394, Loss: 0.3988\n",
      "Batch 18126/35394, Loss: 0.3120\n",
      "Batch 18751/35394, Loss: 0.3708\n",
      "Batch 19376/35394, Loss: 0.3355\n",
      "Batch 20001/35394, Loss: 0.3907\n",
      "Batch 20626/35394, Loss: 0.3471\n",
      "Batch 21251/35394, Loss: 0.3528\n",
      "Batch 21876/35394, Loss: 0.4512\n",
      "Batch 22501/35394, Loss: 0.4514\n",
      "Batch 23126/35394, Loss: 0.3772\n",
      "Batch 23751/35394, Loss: 0.4129\n",
      "Batch 24376/35394, Loss: 0.3334\n",
      "Batch 25001/35394, Loss: 0.3114\n",
      "Batch 25626/35394, Loss: 0.3680\n",
      "Batch 26251/35394, Loss: 0.4083\n",
      "Batch 26876/35394, Loss: 0.3320\n",
      "Batch 27501/35394, Loss: 0.3879\n",
      "Batch 28126/35394, Loss: 0.3429\n",
      "Batch 28751/35394, Loss: 0.4878\n",
      "Batch 29376/35394, Loss: 0.3458\n",
      "Batch 30001/35394, Loss: 0.4138\n",
      "Batch 30626/35394, Loss: 0.4606\n",
      "Batch 31251/35394, Loss: 0.3860\n",
      "Batch 31876/35394, Loss: 0.4074\n",
      "Batch 32501/35394, Loss: 0.2880\n",
      "Batch 33126/35394, Loss: 0.2823\n",
      "Batch 33751/35394, Loss: 0.3940\n",
      "Batch 34376/35394, Loss: 0.3666\n",
      "Batch 35001/35394, Loss: 0.5361\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n",
      "Student Validation Accuracy: 0.5691\n",
      "Epoch 3/100\n",
      "Batch 1/35394, Loss: 0.3743\n",
      "Batch 626/35394, Loss: 0.3618\n",
      "Batch 1251/35394, Loss: 0.2925\n",
      "Batch 1876/35394, Loss: 0.3664\n",
      "Batch 2501/35394, Loss: 0.5050\n",
      "Batch 3126/35394, Loss: 0.3954\n",
      "Batch 3751/35394, Loss: 0.4667\n",
      "Batch 4376/35394, Loss: 0.4262\n",
      "Batch 5001/35394, Loss: 0.3716\n",
      "Batch 5626/35394, Loss: 0.3523\n",
      "Batch 6251/35394, Loss: 0.3355\n",
      "Batch 6876/35394, Loss: 0.3428\n",
      "Batch 7501/35394, Loss: 0.4593\n",
      "Batch 8126/35394, Loss: 0.3047\n",
      "Batch 8751/35394, Loss: 0.4165\n",
      "Batch 9376/35394, Loss: 0.3666\n",
      "Batch 10001/35394, Loss: 0.4780\n",
      "Batch 10626/35394, Loss: 0.3279\n",
      "Batch 11251/35394, Loss: 0.3572\n",
      "Batch 11876/35394, Loss: 0.4269\n",
      "Batch 12501/35394, Loss: 0.3626\n",
      "Batch 13126/35394, Loss: 0.3491\n",
      "Batch 13751/35394, Loss: 0.3321\n",
      "Batch 14376/35394, Loss: 0.3875\n",
      "Batch 15001/35394, Loss: 0.4368\n",
      "Batch 15626/35394, Loss: 0.4299\n",
      "Batch 16251/35394, Loss: 0.3424\n",
      "Batch 16876/35394, Loss: 0.3845\n",
      "Batch 17501/35394, Loss: 0.4169\n",
      "Batch 18126/35394, Loss: 0.3454\n",
      "Batch 18751/35394, Loss: 0.4018\n",
      "Batch 19376/35394, Loss: 0.3754\n",
      "Batch 20001/35394, Loss: 0.4541\n",
      "Batch 20626/35394, Loss: 0.3412\n",
      "Batch 21251/35394, Loss: 0.4366\n",
      "Batch 21876/35394, Loss: 0.3482\n",
      "Batch 22501/35394, Loss: 0.3907\n",
      "Batch 23126/35394, Loss: 0.3487\n",
      "Batch 23751/35394, Loss: 0.3410\n",
      "Batch 24376/35394, Loss: 0.3365\n",
      "Batch 25001/35394, Loss: 0.3540\n",
      "Batch 25626/35394, Loss: 0.4734\n",
      "Batch 26251/35394, Loss: 0.4328\n",
      "Batch 26876/35394, Loss: 0.3986\n",
      "Batch 27501/35394, Loss: 0.3513\n",
      "Batch 28126/35394, Loss: 0.3685\n",
      "Batch 28751/35394, Loss: 0.3615\n",
      "Batch 29376/35394, Loss: 0.4445\n",
      "Batch 30001/35394, Loss: 0.3781\n",
      "Batch 30626/35394, Loss: 0.3685\n",
      "Batch 31251/35394, Loss: 0.3843\n",
      "Batch 31876/35394, Loss: 0.4016\n",
      "Batch 32501/35394, Loss: 0.3407\n",
      "Batch 33126/35394, Loss: 0.3287\n",
      "Batch 33751/35394, Loss: 0.3845\n",
      "Batch 34376/35394, Loss: 0.4048\n",
      "Batch 35001/35394, Loss: 0.3357\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step\n",
      "Student Validation Accuracy: 0.5693\n",
      "Epoch 4/100\n",
      "Batch 1/35394, Loss: 0.3406\n",
      "Batch 626/35394, Loss: 0.3941\n",
      "Batch 1251/35394, Loss: 0.3961\n",
      "Batch 1876/35394, Loss: 0.3816\n",
      "Batch 2501/35394, Loss: 0.3910\n",
      "Batch 3126/35394, Loss: 0.3137\n",
      "Batch 3751/35394, Loss: 0.4770\n",
      "Batch 4376/35394, Loss: 0.3934\n",
      "Batch 5001/35394, Loss: 0.3484\n",
      "Batch 5626/35394, Loss: 0.3834\n",
      "Batch 6251/35394, Loss: 0.3662\n",
      "Batch 6876/35394, Loss: 0.4218\n",
      "Batch 7501/35394, Loss: 0.3172\n",
      "Batch 8126/35394, Loss: 0.3047\n",
      "Batch 8751/35394, Loss: 0.4547\n",
      "Batch 9376/35394, Loss: 0.3884\n",
      "Batch 10001/35394, Loss: 0.3474\n",
      "Batch 10626/35394, Loss: 0.3458\n",
      "Batch 11251/35394, Loss: 0.4026\n",
      "Batch 11876/35394, Loss: 0.4071\n",
      "Batch 12501/35394, Loss: 0.4598\n",
      "Batch 13126/35394, Loss: 0.3925\n",
      "Batch 13751/35394, Loss: 0.3012\n",
      "Batch 14376/35394, Loss: 0.3564\n",
      "Batch 15001/35394, Loss: 0.3027\n",
      "Batch 15626/35394, Loss: 0.3020\n",
      "Batch 16251/35394, Loss: 0.3621\n",
      "Batch 16876/35394, Loss: 0.3962\n",
      "Batch 17501/35394, Loss: 0.4231\n",
      "Batch 18126/35394, Loss: 0.3173\n",
      "Batch 18751/35394, Loss: 0.4059\n",
      "Batch 19376/35394, Loss: 0.4083\n",
      "Batch 20001/35394, Loss: 0.4154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     64\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, student_model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n\u001b[0;32m---> 65\u001b[0m \u001b[43mstudent_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# print every 10000 batches\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:291\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    290\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterations\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:356\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    353\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:419\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m# Run udpate step.\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    426\u001b[0m     )\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:121\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    119\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m    120\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_reduce_sum_gradients(grads_and_vars)\n\u001b[0;32m--> 121\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:135\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:132\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/optimizers/adam.py:133\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    128\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_variable_index(variable)]\n\u001b[1;32m    130\u001b[0m alpha \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m ops\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta_2_power) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta_1_power)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_add(\n\u001b[0;32m--> 133\u001b[0m     m, ops\u001b[38;5;241m.\u001b[39mmultiply(\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1)\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_add(\n\u001b[1;32m    136\u001b[0m     v,\n\u001b[1;32m    137\u001b[0m     ops\u001b[38;5;241m.\u001b[39mmultiply(\n\u001b[1;32m    138\u001b[0m         ops\u001b[38;5;241m.\u001b[39msubtract(ops\u001b[38;5;241m.\u001b[39msquare(gradient), v), \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2\n\u001b[1;32m    139\u001b[0m     ),\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad:\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/ops/numpy.py:5480\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   5478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[1;32m   5479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subtract()\u001b[38;5;241m.\u001b[39msymbolic_call(x1, x2)\n\u001b[0;32m-> 5480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py:493\u001b[0m, in \u001b[0;36melementwise_binary_union.<locals>.wrap_elementwise_binary_union.<locals>.sparse_wrapper\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x2, tf\u001b[38;5;241m.\u001b[39mIndexedSlices):\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# x2 is an IndexedSlices, densify.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x2)\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py:346\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    344\u001b[0m x1 \u001b[38;5;241m=\u001b[39m convert_to_tensor(x1, dtype)\n\u001b[1;32m    345\u001b[0m x2 \u001b[38;5;241m=\u001b[39m convert_to_tensor(x2, dtype)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/ops/math_ops.py:545\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmath.subtract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtract\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    542\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39mregister_binary_elementwise_api\n\u001b[1;32m    543\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubtract\u001b[39m(x, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 545\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:140\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_arg_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m   y_arg_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(arg_names)\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "student_model = build_mlp(input_dim=num_features, output_dim=num_classes)\n",
    "\n",
    "# Knowledge distillation loss for multiclass\n",
    "def knowledge_distillation_loss(y_true, y_pred_student, y_pred_teacher, alpha=0.5, temperature=3):\n",
    "    \"\"\"\n",
    "    y_true: True labels\n",
    "    y_pred_student: Predictions from the student (softmax probabilities)\n",
    "    y_pred_teacher: Predictions from the teacher (softened probabilities)\n",
    "    alpha: Trade-off between true label loss and teacher-student soft label alignment\n",
    "    temperature: Temperature scaling for soft labels\n",
    "    \"\"\"\n",
    "    # True label loss (hard loss)\n",
    "    hard_loss = CategoricalCrossentropy()(y_true, y_pred_student)\n",
    "    \n",
    "    # Soft label loss (KL divergence)\n",
    "    y_teacher_soft = tf.nn.softmax(y_pred_teacher / temperature)\n",
    "    y_student_soft = tf.nn.softmax(y_pred_student / temperature)\n",
    "    soft_loss = tf.keras.losses.KLDivergence()(y_teacher_soft, y_student_soft)\n",
    "    \n",
    "    # Combined loss\n",
    "    return alpha * hard_loss + (1 - alpha) * soft_loss\n",
    "\n",
    "# --------------------------------\n",
    "# 3. Train the Student Model with Teacher Guidance\n",
    "# --------------------------------\n",
    "\n",
    "# Train loop for knowledge distillation\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "temperature = 3\n",
    "alpha = 0.5\n",
    "\n",
    "# Optimizer for student model\n",
    "student_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Checkpoint to save the best student model\n",
    "student_checkpoint = ModelCheckpoint('/work/users/d/d/ddinh/aaco/src/best_student_model.keras', monitor='val_roc_auc', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    # Shuffle training data\n",
    "    indices = np.random.permutation(len(X_class))\n",
    "    X_class_shuffled = X_class[indices]\n",
    "    Y_class_shuffled = Y_class[indices]\n",
    "    \n",
    "    # Mini-batch training\n",
    "    for i in range(0, len(X_class_shuffled), batch_size):\n",
    "        X_batch = X_class_shuffled[i:i+batch_size]\n",
    "        y_batch = Y_class_shuffled[i:i+batch_size]\n",
    "        \n",
    "        # Teacher predictions on the batch\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred_teacher = teacher_model(X_batch, training=False)\n",
    "            y_pred_student = student_model(X_batch, training=True)\n",
    "            \n",
    "            # Compute knowledge distillation loss\n",
    "            loss = knowledge_distillation_loss(y_batch, y_pred_student, y_pred_teacher, alpha, temperature)\n",
    "        \n",
    "        # Backpropagation\n",
    "        grads = tape.gradient(loss, student_model.trainable_weights)\n",
    "        student_optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
    "        # print every 10000 batches\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Batch {i//batch_size + 1}/{len(X_class_shuffled)//batch_size + 1}, Loss: {loss.numpy():.4f}\")\n",
    "    \n",
    "    # Evaluate student after each epoch\n",
    "    y_pred_student = student_model.predict(X_class_val)\n",
    "    y_pred_classes = np.argmax(y_pred_student, axis=1)\n",
    "    accuracy = np.mean(y_pred_classes == np.argmax(Y_class_val, axis=1))\n",
    "    print(f\"Student Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Save the best student model\n",
    "    # student_checkpoint.on_epoch_end(epoch, logs={'val_roc_auc': accuracy})\n",
    "\n",
    "# -------------------------------- \n",
    "# 4. Compare Teacher and Student Performance\n",
    "# --------------------------------\n",
    "# Evaluate teacher on full feature set\n",
    "teacher_accuracy = teacher_model.evaluate(X_class_val, Y_class_val, verbose=0)[1]\n",
    "print(f\"Teacher Test Accuracy (Full Features): {teacher_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate student on reduced feature set\n",
    "y_pred_student = student_model.predict(X_class_val)\n",
    "student_accuracy = np.mean(np.argmax(Y_class_val, axis=1) == np.argmax(test_y_ts, axis=1))\n",
    "print(f\"Student Test Accuracy (Reduced Features): {student_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m35359/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5736 - loss: 0.8772 - prc: 0.4439 - roc_auc: 0.6510\n",
      "Epoch 1: val_roc_auc improved from -inf to 0.67363, saving model to /work/users/d/d/ddinh/aaco/models/mlp_distillation.keras\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1ms/step - accuracy: 0.5737 - loss: 0.8771 - prc: 0.4439 - roc_auc: 0.6510 - val_accuracy: 0.5757 - val_loss: 0.8920 - val_prc: 0.5000 - val_roc_auc: 0.6736\n",
      "Epoch 2/20\n",
      "\u001b[1m35369/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5818 - loss: 0.8279 - prc: 0.4815 - roc_auc: 0.6889\n",
      "Epoch 2: val_roc_auc did not improve from 0.67363\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.5818 - loss: 0.8279 - prc: 0.4815 - roc_auc: 0.6889 - val_accuracy: 0.5725 - val_loss: 0.8912 - val_prc: 0.4997 - val_roc_auc: 0.6732\n",
      "Epoch 3/20\n",
      "\u001b[1m35364/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8257 - prc: 0.4841 - roc_auc: 0.6905\n",
      "Epoch 3: val_roc_auc improved from 0.67363 to 0.67526, saving model to /work/users/d/d/ddinh/aaco/models/mlp_distillation.keras\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8257 - prc: 0.4841 - roc_auc: 0.6905 - val_accuracy: 0.5716 - val_loss: 0.8955 - val_prc: 0.5016 - val_roc_auc: 0.6753\n",
      "Epoch 4/20\n",
      "\u001b[1m35382/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5832 - loss: 0.8257 - prc: 0.4847 - roc_auc: 0.6908\n",
      "Epoch 4: val_roc_auc did not improve from 0.67526\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.5832 - loss: 0.8257 - prc: 0.4847 - roc_auc: 0.6908 - val_accuracy: 0.5718 - val_loss: 0.8904 - val_prc: 0.4997 - val_roc_auc: 0.6706\n",
      "Epoch 5/20\n",
      "\u001b[1m35397/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5822 - loss: 0.8254 - prc: 0.4832 - roc_auc: 0.6900\n",
      "Epoch 5: val_roc_auc did not improve from 0.67526\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5822 - loss: 0.8254 - prc: 0.4832 - roc_auc: 0.6900 - val_accuracy: 0.5744 - val_loss: 0.8841 - val_prc: 0.5022 - val_roc_auc: 0.6736\n",
      "Epoch 6/20\n",
      "\u001b[1m35381/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 0.8252 - prc: 0.4863 - roc_auc: 0.6916\n",
      "Epoch 6: val_roc_auc did not improve from 0.67526\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 0.8252 - prc: 0.4863 - roc_auc: 0.6916 - val_accuracy: 0.5702 - val_loss: 0.8942 - val_prc: 0.5016 - val_roc_auc: 0.6750\n",
      "Epoch 7/20\n",
      "\u001b[1m35387/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8262 - prc: 0.4839 - roc_auc: 0.6903\n",
      "Epoch 7: val_roc_auc improved from 0.67526 to 0.67982, saving model to /work/users/d/d/ddinh/aaco/models/mlp_distillation.keras\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8262 - prc: 0.4839 - roc_auc: 0.6903 - val_accuracy: 0.5796 - val_loss: 0.8824 - val_prc: 0.5031 - val_roc_auc: 0.6798\n",
      "Epoch 8/20\n",
      "\u001b[1m35394/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5824 - loss: 0.8259 - prc: 0.4840 - roc_auc: 0.6906\n",
      "Epoch 8: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5824 - loss: 0.8259 - prc: 0.4840 - roc_auc: 0.6906 - val_accuracy: 0.5734 - val_loss: 0.8827 - val_prc: 0.5019 - val_roc_auc: 0.6765\n",
      "Epoch 9/20\n",
      "\u001b[1m35373/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5827 - loss: 0.8253 - prc: 0.4844 - roc_auc: 0.6906\n",
      "Epoch 9: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5827 - loss: 0.8253 - prc: 0.4844 - roc_auc: 0.6906 - val_accuracy: 0.5700 - val_loss: 0.8958 - val_prc: 0.5046 - val_roc_auc: 0.6792\n",
      "Epoch 10/20\n",
      "\u001b[1m35372/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5826 - loss: 0.8243 - prc: 0.4844 - roc_auc: 0.6908\n",
      "Epoch 10: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5826 - loss: 0.8243 - prc: 0.4844 - roc_auc: 0.6908 - val_accuracy: 0.5762 - val_loss: 0.8866 - val_prc: 0.5034 - val_roc_auc: 0.6762\n",
      "Epoch 11/20\n",
      "\u001b[1m35396/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 0.8264 - prc: 0.4839 - roc_auc: 0.6906\n",
      "Epoch 11: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 0.8264 - prc: 0.4839 - roc_auc: 0.6906 - val_accuracy: 0.5798 - val_loss: 0.8859 - val_prc: 0.5039 - val_roc_auc: 0.6739\n",
      "Epoch 12/20\n",
      "\u001b[1m35359/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8257 - prc: 0.4848 - roc_auc: 0.6909\n",
      "Epoch 12: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8257 - prc: 0.4848 - roc_auc: 0.6909 - val_accuracy: 0.5784 - val_loss: 0.8914 - val_prc: 0.5015 - val_roc_auc: 0.6738\n",
      "Epoch 13/20\n",
      "\u001b[1m35377/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5819 - loss: 0.8266 - prc: 0.4844 - roc_auc: 0.6901\n",
      "Epoch 13: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5819 - loss: 0.8266 - prc: 0.4844 - roc_auc: 0.6901 - val_accuracy: 0.5753 - val_loss: 0.8857 - val_prc: 0.5026 - val_roc_auc: 0.6748\n",
      "Epoch 14/20\n",
      "\u001b[1m35370/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5825 - loss: 0.8258 - prc: 0.4842 - roc_auc: 0.6903\n",
      "Epoch 14: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5825 - loss: 0.8258 - prc: 0.4842 - roc_auc: 0.6903 - val_accuracy: 0.5707 - val_loss: 0.8865 - val_prc: 0.5021 - val_roc_auc: 0.6754\n",
      "Epoch 15/20\n",
      "\u001b[1m35371/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 0.8262 - prc: 0.4836 - roc_auc: 0.6902\n",
      "Epoch 15: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 0.8262 - prc: 0.4836 - roc_auc: 0.6902 - val_accuracy: 0.5744 - val_loss: 0.8844 - val_prc: 0.5047 - val_roc_auc: 0.6753\n",
      "Epoch 16/20\n",
      "\u001b[1m35376/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5815 - loss: 0.8265 - prc: 0.4837 - roc_auc: 0.6900\n",
      "Epoch 16: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5815 - loss: 0.8265 - prc: 0.4837 - roc_auc: 0.6900 - val_accuracy: 0.5705 - val_loss: 0.8868 - val_prc: 0.5042 - val_roc_auc: 0.6766\n",
      "Epoch 17/20\n",
      "\u001b[1m35365/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8260 - prc: 0.4840 - roc_auc: 0.6904\n",
      "Epoch 17: val_roc_auc did not improve from 0.67982\n",
      "\u001b[1m35402/35402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8260 - prc: 0.4840 - roc_auc: 0.6904 - val_accuracy: 0.5759 - val_loss: 0.8898 - val_prc: 0.5053 - val_roc_auc: 0.6781\n",
      "Epoch 17: early stopping\n",
      "Loss: 0.8898029327392578, Accuracy: 0.5758602023124695, ROC AUC: 0.6781113147735596, PRC: 0.505259096622467\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "TOTAL_FEATURES = train_x_ts.shape[-1]\n",
    "HIDDEN_DIM = 10\n",
    "NUM_CLASSES = train_y_ts.shape[-1]\n",
    "DROPOUT_RATE = 0.5\n",
    "\n",
    "def create_mlp():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(TOTAL_FEATURES,)),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')  \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model = create_mlp()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='roc_auc', multi_label=True, num_labels=3), AUC(name='prc', curve='PR', multi_label=True, num_labels=3)]\n",
    "    # metrics=['accuracy', AUC(name='roc_auc'), AUC(name='prc', curve='PR')]\n",
    ")\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=20, batch_size=32):\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        '/work/users/d/d/ddinh/aaco/models/mlp_distillation.keras',  \n",
    "        monitor='val_roc_auc',\n",
    "        mode='max',  \n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_roc_auc', \n",
    "        mode='max', \n",
    "        patience=10,  \n",
    "        verbose=1\n",
    "    )\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[checkpoint, early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    loss, accuracy, roc_auc, prc = model.evaluate(X, y, verbose=0)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}, ROC AUC: {roc_auc}, PRC: {prc}\")\n",
    "    return loss, accuracy, roc_auc\n",
    "\n",
    "# history = train_model(model, train_x_ts, train_y_ts, val_x_ts, val_y_ts)\n",
    "# evaluate_model(model, val_x_ts, val_y_ts)\n",
    "history = train_model(model, X_class, Y_class, X_class_val, Y_class_val)\n",
    "evaluate_model(model, X_class_val, Y_class_val)\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['roc_auc'])\n",
    "    plt.plot(history.history['val_roc_auc'])\n",
    "    plt.title('model roc_auc')\n",
    "    plt.ylabel('roc_auc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['prc'])\n",
    "    plt.plot(history.history['val_prc'])\n",
    "    plt.title('model prc')\n",
    "    plt.ylabel('prc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_history(history)\n",
    "#  val_prc: 0.5998 - val_roc_auc: 0.7917\n",
    "\n",
    "# val_prc: 0.5031 - val_roc_auc: 0.6773\n",
    "#  val_prc: 0.5188 - val_roc_auc: 0.6819 15 numhidden\n",
    "\n",
    "# val_prc: 0.5257 - val_roc_auc: 0.6897 20 numhidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/work/users/d/d/ddinh/aaco/models/mlp_uncertainty_part2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_adni_data()\n",
    "x = dataset.x\n",
    "y = dataset.y\n",
    "\n",
    "mask_nan = np.isnan(x)\n",
    "\n",
    "x[mask_nan] = 0\n",
    "\n",
    "num_ts = y.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06387226 0.64271457 0.29341317]\n",
      "[0.08805668 0.61234818 0.29959514]\n",
      "[0.10761421 0.59187817 0.30050761]\n",
      "[0.125      0.58974359 0.28525641]\n",
      "[0.16613757 0.54179894 0.29206349]\n",
      "[0.13573883 0.56872852 0.29553265]\n",
      "[0.178125  0.5796875 0.2421875]\n",
      "[0.18283582 0.53731343 0.27985075]\n",
      "[0.17350746 0.46455224 0.3619403 ]\n",
      "[0.18235294 0.45294118 0.36470588]\n",
      "[0.18596491 0.49473684 0.31929825]\n",
      "[0.17098446 0.43005181 0.39896373]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_ts):\n",
    "    count = [0,0,0]\n",
    "    total = 0\n",
    "    for j in range(y.shape[0]):\n",
    "        for k in range(3):\n",
    "            if y[j,i,k] == 1:\n",
    "                count[k] += 1\n",
    "                total += 1\n",
    "    count = np.array(count)\n",
    "    print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13054449 0.56998672 0.29946879]\n"
     ]
    }
   ],
   "source": [
    "count = [0,0,0]\n",
    "total = 0\n",
    "for i in range(num_ts):\n",
    "    for j in range(y.shape[0]):\n",
    "        for k in range(3):\n",
    "            if y[j,i,k] == 1:\n",
    "                count[k] += 1\n",
    "                total += 1\n",
    "count = np.array(count)\n",
    "print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40976380572188953"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_nan = x==0\n",
    "# get the number of nan values\n",
    "total = mask_nan.sum()\n",
    "probability = total / x.size\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((801, 12, 4), (201, 12, 4), (801, 12, 3), (201, 12, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into train and test sets 80/20 with random seed 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = prepare_time_series(torch.Tensor([range(0,12)] * x_train.shape[0]), torch.Tensor(x_train))[1]\n",
    "# y_train = prepare_time_series(torch.Tensor([range(0,12)] * y_train.shape[0]), torch.Tensor(y_train))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = torch.cat([x_train, x_train[:, [-1]]], dim=-2).numpy()\n",
    "# y_train = torch.cat([y_train, y_train[:, [-1]]], dim=-2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.round(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ts = []\n",
    "# y_ts = []\n",
    "\n",
    "# for i in range(num_ts): \n",
    "#     x_temp = np.zeros_like(x_train)\n",
    "#     x_temp[:, :i+1, :] = x_train[:, :i+1, :]\n",
    "#     x_ts.append(x_temp)    \n",
    "#     y_ts.append(y_train)\n",
    "# x_ts = np.concatenate(x_ts, axis=0)\n",
    "# y_ts = np.concatenate(y_ts, axis=0)\n",
    "# x_ts.shape, y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"temp\n",
    "\"\"\"\n",
    "x_ts = x_train\n",
    "y_ts = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "for item in x_ts:\n",
    "    x_all.append(item.flatten('F'))\n",
    "x_train = np.array(x_all)\n",
    "y_train = y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_masks(inputs, pm=0.2, pd_m=0.4):\n",
    "    inputs = np.copy(inputs).reshape(-1, 12, 4)\n",
    "    n, T, M = inputs.shape\n",
    "    masked_inputs = inputs.copy()\n",
    "\n",
    "    mask_m1 = np.random.binomial(1, pm, size=(n, T, M))\n",
    "    \n",
    "    t_max = np.random.randint(0, T, size=n)\n",
    "    mask_m2 = np.ones((n, T, M))\n",
    "    for i in range(n):\n",
    "        mask_m2[i, t_max[i]:] = 0\n",
    "    \n",
    "    modality_drop = np.random.binomial(1, pd_m, size=(n, M))\n",
    "    mask_m3 = np.ones((n, T, M))\n",
    "    for m in range(M):\n",
    "        mask_m3[:, :, m] *= modality_drop[:, m].reshape(-1, 1)\n",
    "\n",
    "    final_mask = mask_m1 * mask_m2 * mask_m3\n",
    "    masked_inputs *= final_mask\n",
    "\n",
    "    return masked_inputs, final_mask.reshape(n, -1)\n",
    "\n",
    "pm = 0.2\n",
    "pd_m = 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masksper = 256 * 2\n",
    "d = x_train.shape[1]\n",
    "X_class = np.concatenate([x_train]*masksper, 0)\n",
    "Y_class = np.concatenate([y_train]*masksper, 0)\n",
    "# B = np.concatenate(\n",
    "# [np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class.shape[0])],\n",
    "# 1)\n",
    "# B = np.float32(B.T)\n",
    "\n",
    "_, B = apply_masks(X_class, pm, pd_m)\n",
    "    \n",
    "\"\"\"\n",
    "remove for interpolation\n",
    "\"\"\"\n",
    "zero_mask = X_class == 0\n",
    "B[zero_mask] = 0\n",
    "\n",
    "# # remove 0 mask\n",
    "mask_nonzero = np.sum(B, axis=1) != 0\n",
    "B = B[mask_nonzero]\n",
    "X_class = X_class[mask_nonzero]\n",
    "Y_class = Y_class[mask_nonzero]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_nan = X_class == 0\n",
    "# B[mask_nan] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = np.concatenate((X_class*B, B), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213901, 96), (213901, 12, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_class.shape, Y_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "for i in range(B.shape[0]):\n",
    "    b = B[i]\n",
    "    temp = -1\n",
    "    for j in range(4):\n",
    "        part = b[num_ts*j:num_ts*(j+1)]\n",
    "        max_index = np.where(part == 1)[0]\n",
    "        if len(max_index) > 0:\n",
    "            max_index = max_index[-1]\n",
    "            if max_index > temp:\n",
    "                temp = max_index\n",
    "    location.append(temp)\n",
    "    \n",
    "location = np.array(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 16433]\n",
      " [    1 22512]\n",
      " [    2 24842]\n",
      " [    3 30042]\n",
      " [    4 27878]\n",
      " [    5 18594]\n",
      " [    6 21267]\n",
      " [    7  9046]\n",
      " [    8 19186]\n",
      " [    9  5576]\n",
      " [   10 10502]\n",
      " [   11  8023]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(location, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = []\n",
    "for i in range(Y_class.shape[0]):\n",
    "    y_location = Y_class[i, location[i]]\n",
    "    mask_nan = np.isnan(y_location)\n",
    "    y_location[mask_nan] = 0\n",
    "    y_temp.append(y_location)\n",
    "y_temp = np.array(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove y with nan values\n",
    "mask_zero = np.sum(y_temp, axis=1) != 0\n",
    "X_class = X_class[mask_zero]\n",
    "Y_class = y_temp[mask_zero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_class = np.argmax(Y_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/xgboost/core.py:158: UserWarning: [10:37:46] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/xgboost/core.py:158: UserWarning: [10:37:46] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;gpu&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=256, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;gpu&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=256, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='gpu', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=256, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train classifier\n",
    "est = XGBClassifier(n_estimators=256, device='gpu')\n",
    "est.fit(X_class, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/xgboost/core.py:158: UserWarning: [10:39:02] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# est.save_model('/work/users/d/d/ddinh/aaco/models/adni_different_masking.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2412, 12, 4), (2412, 12, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts_val = []\n",
    "y_ts_val = []\n",
    "\n",
    "for i in range(num_ts): \n",
    "    x_temp = np.zeros_like(x_val)\n",
    "    x_temp[:, :i+1, :] = x_val[:, :i+1, :]\n",
    "    x_ts_val.append(x_temp)    \n",
    "    y_ts_val.append(y_val)\n",
    "x_ts_val = np.concatenate(x_ts_val, axis=0)\n",
    "y_ts_val = np.concatenate(y_ts_val, axis=0)\n",
    "x_ts_val.shape, y_ts_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_val = []\n",
    "for item in x_ts_val:\n",
    "    x_all_val.append(item.flatten('F'))\n",
    "x_val = np.array(x_all_val)\n",
    "y_val = y_ts_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "masksper = 1\n",
    "d = x_val.shape[1]\n",
    "X_class_val = np.concatenate([x_val]*masksper, 0)\n",
    "Y_class_val = np.concatenate([y_val]*masksper, 0)\n",
    "B_val = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class_val.shape[0])],\n",
    "1)\n",
    "B_val = np.float32(B_val.T)\n",
    "\n",
    "# B_val = np.ones_like(B_val)\n",
    "\n",
    "zero_mask_val = X_class_val == 0\n",
    "B_val[zero_mask_val] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero_val = np.sum(B_val, axis=1) != 0\n",
    "B_val = B_val[mask_nonzero_val]\n",
    "X_class_val = X_class_val[mask_nonzero_val]\n",
    "Y_class_val = Y_class_val[mask_nonzero_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_val = []\n",
    "for i in range(B_val.shape[0]):\n",
    "    b = B_val[i]\n",
    "    temp = -1\n",
    "    for j in range(4):\n",
    "        part = b[num_ts*j:num_ts*(j+1)]\n",
    "        max_index = np.where(part == 1)[0]\n",
    "        if len(max_index) > 0:\n",
    "            max_index = max_index[-1]\n",
    "            if max_index > temp:\n",
    "                temp = max_index\n",
    "    location_val.append(temp)\n",
    "    \n",
    "location_val = np.array(location_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp_val = []\n",
    "for i in range(Y_class_val.shape[0]):\n",
    "    y_location_val = Y_class_val[i, location_val[i]]\n",
    "    mask_nan_val = np.isnan(y_location_val)\n",
    "    y_location_val[mask_nan_val] = 0\n",
    "    y_temp_val.append(y_location_val)\n",
    "y_temp_val = np.array(y_temp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove y with nan values for validation set\n",
    "mask_zero_val = np.sum(y_temp_val, axis=1) != 0\n",
    "X_class_val = X_class_val[mask_zero_val]\n",
    "Y_class_val = y_temp_val[mask_zero_val]\n",
    "B_val = B_val[mask_zero_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2246,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_zero_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_val = np.concatenate((X_class_val*B_val, B_val), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = est.predict_proba(X_class_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5409617097061442\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.argmax(val_preds, 1)==np.argmax(Y_class_val, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5109105973299515\n",
      "0.7030657167468642\n"
     ]
    }
   ],
   "source": [
    "# this is temoprary evaluation, since it's not really correct.\n",
    "# it should be evaluated on the accumulated predictions, not the individual predictions like this rolling out \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "pr_auc_macro = average_precision_score(Y_class_val, val_preds, average=\"macro\")\n",
    "print(pr_auc_macro)\n",
    "\n",
    "roc_auc_macro = roc_auc_score(Y_class_val, val_preds, average=\"macro\", multi_class=\"ovr\")\n",
    "print(roc_auc_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.037846"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(B_val.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "# 0.5057228523811975\n",
    "# 0.6798018971723648\n",
    "\n",
    "# masking from a2mt paper\n",
    "# 0.5109105973299515\n",
    "# 0.7030657167468642"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
