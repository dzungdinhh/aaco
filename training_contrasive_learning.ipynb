{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 19:52:56.397040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-15 19:52:56.410655: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-15 19:52:56.414797: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-15 19:52:56.426128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-15 19:52:58.104055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('/work/users/d/d/ddinh/aaco/src')\n",
    "from load_dataset import load_adni_data\n",
    "from cvar_sensing.utils import prepare_time_series, batch_interp_nd\n",
    "import torch\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    ds = load_adni_data(file_path=file_path)\n",
    "    x = ds.x\n",
    "    y = ds.y\n",
    "    mask_nan = np.isnan(x)\n",
    "    x[mask_nan] = 0\n",
    "    \n",
    "    mask_nan_y = np.isnan(y)\n",
    "    y[mask_nan_y] = 0\n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = load_data(\"/work/users/d/d/ddinh/aaco/input_data/train_data.npz\")\n",
    "val_x, val_y = load_data(\"/work/users/d/d/ddinh/aaco/input_data/val_data.npz\")\n",
    "test_x, test_y = load_data(\"/work/users/d/d/ddinh/aaco/input_data/test_data.npz\")\n",
    "\n",
    "num_ts = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts(x, y): \n",
    "    x_data = np.copy(x)\n",
    "    y_data = np.copy(y)\n",
    "    x_ts = []\n",
    "    y_ts = []\n",
    "    masks = []\n",
    "    idx_table = []\n",
    "    \n",
    "    for i in range(num_ts):\n",
    "        x_zero = np.zeros(x_data.shape)\n",
    "        x_zero[:, :i+1] = x_data[:, :i+1,:]\n",
    "        \n",
    "        non_zero_mask = np.sum(y_data[:,i,:], axis=1) != 0\n",
    "        \n",
    "        x_filtered = np.transpose(x_zero[non_zero_mask,:,:], (0, 2, 1)).reshape(-1, x_data.shape[1] * x_data.shape[2])\n",
    "        \n",
    "        x_filtered = np.concatenate([x_filtered, np.repeat(i, x_filtered.shape[0])[:, None]], axis=1)\n",
    "        \n",
    "        x_ts.append(x_filtered)\n",
    "        y_ts.append(y_data[non_zero_mask, i, :])\n",
    "        # keep the index of the original data\n",
    "        idx_table.append(np.where(non_zero_mask)[0])\n",
    "            \n",
    "    x_ts = np.concatenate(x_ts, axis=0)\n",
    "    y_ts = np.concatenate(y_ts, axis=0)\n",
    "    idx_table = np.concatenate(idx_table, axis=0)\n",
    "    \n",
    "    return x_ts, y_ts, idx_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = np.transpose(train_x, (0, 2, 1)).reshape(-1, train_x.shape[1] * train_x.shape[2])\n",
    "# val_x = np.transpose(val_x, (0, 2, 1)).reshape(-1, val_x.shape[1] * val_x.shape[2])\n",
    "# test_x = np.transpose(test_x, (0, 2, 1)).reshape(-1, test_x.shape[1] * test_x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6046, 49), (6046,), (6046,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ts, train_y_ts, train_idx_table = get_ts(train_x, train_y)\n",
    "val_x_ts, val_y_ts, val_idx_table = get_ts(val_x, val_y)\n",
    "test_x_ts, test_y_ts, test_idx_table = get_ts(test_x, test_y)\n",
    "\n",
    "# concatenate train and val\n",
    "train_x_ts = np.concatenate([train_x_ts, val_x_ts], axis=0)\n",
    "train_y_ts = np.concatenate([train_y_ts, val_y_ts], axis=0)\n",
    "train_idx_table = np.concatenate([train_idx_table, val_idx_table], axis=0)\n",
    "\n",
    "train_y_ts = np.argmax(train_y_ts, axis=1)  # shape (n,)\n",
    "val_y_ts = np.argmax(val_y_ts, axis=1)  # shape (n,)\n",
    "test_y_ts = np.argmax(test_y_ts, axis=1)  # shape (n,)\n",
    "\n",
    "train_x_ts.shape, train_y_ts.shape, train_idx_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.load_model('/work/users/d/d/ddinh/aaco/models/mlp.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: fix the build_pairs so the idx_table is used correclty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.4513 - class_loss: 1.0463 - contrastive_loss: 0.3320 - loss: 1.3783 - pr_auc: 0.3426 - roc_auc: 0.5190 - val_accuracy: 0.5893 - val_class_loss: 0.9355 - val_contrastive_loss: 0.2633 - val_loss: 1.1988 - val_pr_auc: 0.3951 - val_roc_auc: 0.5946\n",
      "Epoch 2/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5650 - class_loss: 0.9377 - contrastive_loss: 0.2540 - loss: 1.1917 - pr_auc: 0.4193 - roc_auc: 0.6284 - val_accuracy: 0.5794 - val_class_loss: 0.9184 - val_contrastive_loss: 0.2471 - val_loss: 1.1656 - val_pr_auc: 0.4508 - val_roc_auc: 0.6390\n",
      "Epoch 3/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5675 - class_loss: 0.9105 - contrastive_loss: 0.2535 - loss: 1.1640 - pr_auc: 0.4605 - roc_auc: 0.6620 - val_accuracy: 0.5526 - val_class_loss: 0.9212 - val_contrastive_loss: 0.2453 - val_loss: 1.1665 - val_pr_auc: 0.4829 - val_roc_auc: 0.6601\n",
      "Epoch 4/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5732 - class_loss: 0.8774 - contrastive_loss: 0.2500 - loss: 1.1274 - pr_auc: 0.4941 - roc_auc: 0.6946 - val_accuracy: 0.5690 - val_class_loss: 0.8892 - val_contrastive_loss: 0.2495 - val_loss: 1.1387 - val_pr_auc: 0.4791 - val_roc_auc: 0.6693\n",
      "Epoch 5/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5617 - class_loss: 0.8728 - contrastive_loss: 0.2460 - loss: 1.1188 - pr_auc: 0.4879 - roc_auc: 0.6878 - val_accuracy: 0.5609 - val_class_loss: 0.8710 - val_contrastive_loss: 0.2471 - val_loss: 1.1182 - val_pr_auc: 0.5061 - val_roc_auc: 0.6833\n",
      "Epoch 6/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5676 - class_loss: 0.8557 - contrastive_loss: 0.2484 - loss: 1.1041 - pr_auc: 0.5015 - roc_auc: 0.6987 - val_accuracy: 0.5701 - val_class_loss: 0.8608 - val_contrastive_loss: 0.2431 - val_loss: 1.1038 - val_pr_auc: 0.5131 - val_roc_auc: 0.6906\n",
      "Epoch 7/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5715 - class_loss: 0.8542 - contrastive_loss: 0.2463 - loss: 1.1005 - pr_auc: 0.5036 - roc_auc: 0.6984 - val_accuracy: 0.5885 - val_class_loss: 0.8458 - val_contrastive_loss: 0.2466 - val_loss: 1.0924 - val_pr_auc: 0.5332 - val_roc_auc: 0.7028\n",
      "Epoch 8/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5793 - class_loss: 0.8314 - contrastive_loss: 0.2419 - loss: 1.0733 - pr_auc: 0.5175 - roc_auc: 0.7133 - val_accuracy: 0.5964 - val_class_loss: 0.8467 - val_contrastive_loss: 0.2377 - val_loss: 1.0844 - val_pr_auc: 0.5130 - val_roc_auc: 0.6907\n",
      "Epoch 9/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5730 - class_loss: 0.8440 - contrastive_loss: 0.2404 - loss: 1.0844 - pr_auc: 0.5089 - roc_auc: 0.7009 - val_accuracy: 0.5906 - val_class_loss: 0.8354 - val_contrastive_loss: 0.2461 - val_loss: 1.0815 - val_pr_auc: 0.5267 - val_roc_auc: 0.6982\n",
      "Epoch 10/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5861 - class_loss: 0.8217 - contrastive_loss: 0.2428 - loss: 1.0645 - pr_auc: 0.5240 - roc_auc: 0.7131 - val_accuracy: 0.5776 - val_class_loss: 0.8487 - val_contrastive_loss: 0.2424 - val_loss: 1.0911 - val_pr_auc: 0.5180 - val_roc_auc: 0.6972\n",
      "Epoch 11/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5793 - class_loss: 0.8357 - contrastive_loss: 0.2402 - loss: 1.0759 - pr_auc: 0.5247 - roc_auc: 0.7157 - val_accuracy: 0.5802 - val_class_loss: 0.8458 - val_contrastive_loss: 0.2319 - val_loss: 1.0777 - val_pr_auc: 0.5339 - val_roc_auc: 0.7019\n",
      "Epoch 12/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5757 - class_loss: 0.8265 - contrastive_loss: 0.2354 - loss: 1.0619 - pr_auc: 0.5268 - roc_auc: 0.7129 - val_accuracy: 0.5979 - val_class_loss: 0.8396 - val_contrastive_loss: 0.2400 - val_loss: 1.0796 - val_pr_auc: 0.5327 - val_roc_auc: 0.7037\n",
      "Epoch 13/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5882 - class_loss: 0.8172 - contrastive_loss: 0.2380 - loss: 1.0552 - pr_auc: 0.5291 - roc_auc: 0.7194 - val_accuracy: 0.5930 - val_class_loss: 0.8290 - val_contrastive_loss: 0.2342 - val_loss: 1.0632 - val_pr_auc: 0.5333 - val_roc_auc: 0.7056\n",
      "Epoch 14/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5872 - class_loss: 0.8187 - contrastive_loss: 0.2367 - loss: 1.0554 - pr_auc: 0.5361 - roc_auc: 0.7202 - val_accuracy: 0.5784 - val_class_loss: 0.8417 - val_contrastive_loss: 0.2350 - val_loss: 1.0767 - val_pr_auc: 0.5308 - val_roc_auc: 0.7090\n",
      "Epoch 15/15\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5758 - class_loss: 0.8135 - contrastive_loss: 0.2392 - loss: 1.0527 - pr_auc: 0.5232 - roc_auc: 0.7154 - val_accuracy: 0.5807 - val_class_loss: 0.8551 - val_contrastive_loss: 0.2348 - val_loss: 1.0899 - val_pr_auc: 0.5139 - val_roc_auc: 0.6978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7c932d2250>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Hyperparameters\n",
    "# -------------------------------------------------------\n",
    "EMBED_DIM = 20         # Embedding dimension\n",
    "NUM_CLASSES = 3\n",
    "MARGIN = 1.0\n",
    "LAMBDA_CONTRAST = 1.0\n",
    "LAMBDA_CLASS = 1.0\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "num_samples = train_x_ts.shape[0]\n",
    "num_features = train_x_ts.shape[1]\n",
    "\n",
    "X = train_x_ts\n",
    "y = train_y_ts  # assumed shape (num_samples,); if it was (num_samples, 3), convert via np.argmax(...)\n",
    "\n",
    "# Separate validation data\n",
    "X_val = val_x_ts     # shape (num_val_samples, num_features)\n",
    "y_val = val_y_ts     # shape (num_val_samples,)\n",
    "\n",
    "def random_feature_mask(batch_x):\n",
    "    \"\"\"\n",
    "    Takes a batch of shape (batch_size, num_features) \n",
    "    and applies random masks to the first (num_features-1) columns.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid in-place modification of original data\n",
    "    temp_x = batch_x.copy()\n",
    "    \n",
    "    # Build a mask for each row in the batch\n",
    "    mask_list = []\n",
    "    for _ in range(batch_x.shape[0]):\n",
    "        # Randomly pick how many columns to sum from identity permutation\n",
    "        n_cols = np.random.randint(1, num_features)  # or num_features-1\n",
    "        # Permute (num_features-1) identity matrix, sum slice of columns\n",
    "        mask_vec = np.sum(np.random.permutation(np.eye(num_features-1))[:, :n_cols-1], axis=1, keepdims=True)\n",
    "        mask_list.append(mask_vec)\n",
    "\n",
    "    # Concatenate into (batch_size, num_features-1)\n",
    "    mask = np.concatenate(mask_list, axis=1).T.astype(np.float32)\n",
    "\n",
    "    # Zero out mask where the original input was zero\n",
    "    zero_input = temp_x[:, :num_features-1] == 0\n",
    "    mask[zero_input] = 0\n",
    "    \n",
    "    temp_x[:, :num_features-1] *= mask\n",
    "    return temp_x\n",
    "\n",
    "def pair_generator(X, y, batch_size, num_features, p_same_sample=0.3, train_idx_table=None):\n",
    "    \"\"\"\n",
    "    Yields ([batch_x1, batch_x2], [contrast_labels, class_labels]) one batch at a time.\n",
    "    Re-samples the random mask *every iteration* (no pre-generation).\n",
    "    \"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    while True:\n",
    "        batch_x1 = np.zeros((batch_size, num_features), dtype=np.float32)\n",
    "        batch_x2 = np.zeros((batch_size, num_features), dtype=np.float32)\n",
    "        batch_labels = np.zeros((batch_size,), dtype=np.float32)         \n",
    "        batch_class_labels = np.zeros((batch_size,), dtype=np.int32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Decide positive vs negative pair\n",
    "            if i < batch_size // 2:\n",
    "                # Positive pair\n",
    "                if np.random.rand() < p_same_sample:\n",
    "                    # Option A: same sample, different random masks\n",
    "                    idx = np.random.randint(0, num_samples)\n",
    "                    batch_x1[i] = random_feature_mask(X[idx:idx+1])\n",
    "                    batch_x2[i] = random_feature_mask(X[idx:idx+1])\n",
    "                    batch_labels[i] = 1.0\n",
    "                    batch_class_labels[i] = y[idx]\n",
    "                else:\n",
    "                    # Option B: different samples, same class\n",
    "                    while True:\n",
    "                        idx1 = np.random.randint(0, num_samples)\n",
    "                        idx2 = np.random.randint(0, num_samples)\n",
    "                        if y[idx1] == y[idx2] and idx1 != idx2:\n",
    "                            if train_idx_table is not None and (train_idx_table[idx1] == train_idx_table[idx2]):\n",
    "                                continue\n",
    "                            break\n",
    "                    batch_x1[i] = random_feature_mask(X[idx1:idx1+1])\n",
    "                    batch_x2[i] = random_feature_mask(X[idx2:idx2+1])\n",
    "                    batch_labels[i] = 1.0\n",
    "                    batch_class_labels[i] = y[idx1]\n",
    "            else:\n",
    "                # Negative pair\n",
    "                while True:\n",
    "                    idx1 = np.random.randint(0, num_samples)\n",
    "                    idx2 = np.random.randint(0, num_samples)\n",
    "                    if y[idx1] != y[idx2] and idx1 != idx2:\n",
    "                        if train_idx_table is not None and (train_idx_table[idx1] == train_idx_table[idx2]):\n",
    "                            continue\n",
    "                        break\n",
    "                batch_x1[i] = random_feature_mask(X[idx1:idx1+1])\n",
    "                batch_x2[i] = random_feature_mask(X[idx2:idx2+1])\n",
    "                batch_labels[i] = 0.0\n",
    "                batch_class_labels[i] = y[idx1]\n",
    "\n",
    "        yield ((batch_x1, batch_x2), (batch_labels, batch_class_labels))\n",
    "\n",
    "\n",
    "\n",
    "# Create the training dataset with from_generator, infinite\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: pair_generator(X, y, BATCH_SIZE, num_features, p_same_sample=0.3, train_idx_table=train_idx_table),\n",
    "    output_signature = (\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None, num_features), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, num_features), dtype=tf.float32),\n",
    "        ),\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        )\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: pair_generator(X_val, y_val, BATCH_SIZE, num_features, p_same_sample=0.3, train_idx_table=val_idx_table),\n",
    "    output_signature = (\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None, num_features), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, num_features), dtype=tf.float32),\n",
    "        ),\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        )\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Embedding Network + Classification Head Combined\n",
    "# -------------------------------------------------------\n",
    "\n",
    "class L2NormalizeLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2NormalizeLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.l2_normalize(inputs, axis=1)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(L2NormalizeLayer, self).get_config()\n",
    "        return base_config\n",
    "\n",
    "def create_embedding_and_classification(input_shape=(num_features,), embed_dim=EMBED_DIM, num_classes=NUM_CLASSES):\n",
    "    \"\"\"Returns a Keras model that outputs BOTH the embedding z and class logits.\"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Dense(10, activation='relu')(inputs)\n",
    "    x = layers.Dense(10, activation='relu')(x)\n",
    "    z = layers.Dense(embed_dim, activation=None)(x)\n",
    "    # L2 normalize via a Lambda layer\n",
    "    z_norm = L2NormalizeLayer()(z)\n",
    "\n",
    "    \n",
    "    # Classification head on top of embedding\n",
    "    class_logits = layers.Dense(num_classes, activation=None, name='class_logits')(z_norm)\n",
    "    # We output the embedding (z_norm) and the class logits\n",
    "    model = keras.Model(inputs, outputs=[z_norm, class_logits], name=\"EmbeddingPlusClass\")\n",
    "    return model\n",
    "\n",
    "base_network = create_embedding_and_classification()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Siamese Model\n",
    "# -------------------------------------------------------\n",
    "input_a = keras.Input(shape=(num_features,), name='input_a')\n",
    "input_b = keras.Input(shape=(num_features,), name='input_b')\n",
    "\n",
    "z1, class_logits_a = base_network(input_a)\n",
    "z2, _ = base_network(input_b)\n",
    "\n",
    "siamese_model = keras.Model(inputs=[input_a, input_b],\n",
    "                            outputs=[z1, z2, class_logits_a],\n",
    "                            name=\"AFA_Contrastive_Siamese\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Contrastive Loss\n",
    "# -------------------------------------------------------\n",
    "def contrastive_loss(y_true, z1, z2, margin=MARGIN):\n",
    "    distances = tf.reduce_sum(tf.square(z1 - z2), axis=1)\n",
    "    positive_loss = y_true * distances\n",
    "    negative_loss = (1 - y_true) * tf.square(tf.maximum(0.0, margin - tf.sqrt(distances + 1e-7)))\n",
    "    return tf.reduce_mean(positive_loss + negative_loss)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Custom Training (Subclassed) + Extra Metrics (ROC AUC, PR AUC)\n",
    "# -------------------------------------------------------\n",
    "class AFAContrastiveTrainer(keras.Model):\n",
    "    def __init__(self, siamese_model, margin=MARGIN, lambda_contrast=1.0, lambda_class=1.0):\n",
    "        super().__init__()\n",
    "        self.siamese_model = siamese_model\n",
    "        self.margin = margin\n",
    "        self.lambda_contrast = lambda_contrast\n",
    "        self.lambda_class = lambda_class\n",
    "\n",
    "        # Main metrics\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"contrastive_loss\")\n",
    "        self.class_loss_tracker = keras.metrics.Mean(name=\"class_loss\")\n",
    "        self.acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "\n",
    "        # Extra metrics: multi-label ROC AUC & PR AUC for a 3-class problem\n",
    "        # We'll treat each class as separate label => multi_label=True, num_labels=NUM_CLASSES\n",
    "        self.roc_auc = tf.keras.metrics.AUC(curve='ROC', multi_label=True, num_labels=NUM_CLASSES, name='roc_auc')\n",
    "        self.pr_auc = tf.keras.metrics.AUC(curve='PR', multi_label=True, num_labels=NUM_CLASSES, name='pr_auc')\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (x1, x2), (contrast_labels, class_labels) = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z1, z2, class_logits = self.siamese_model([x1, x2], training=True)\n",
    "            # Contrastive loss\n",
    "            c_loss = contrastive_loss(contrast_labels, z1, z2, margin=self.margin)\n",
    "            # Classification loss\n",
    "            class_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "            cl_loss = class_loss_fn(class_labels, class_logits)\n",
    "            total_loss = self.lambda_contrast * c_loss + self.lambda_class * cl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.siamese_model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.siamese_model.trainable_variables))\n",
    "\n",
    "        # Update metrics\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.contrastive_loss_tracker.update_state(c_loss)\n",
    "        self.class_loss_tracker.update_state(cl_loss)\n",
    "        self.acc_metric.update_state(class_labels, class_logits)\n",
    "\n",
    "        # For ROC/PR AUC, we need probabilities and one-hot labels\n",
    "        probs = tf.nn.softmax(class_logits, axis=1)\n",
    "        labels_onehot = tf.one_hot(class_labels, depth=NUM_CLASSES)\n",
    "        self.roc_auc.update_state(labels_onehot, probs)\n",
    "        self.pr_auc.update_state(labels_onehot, probs)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"contrastive_loss\": self.contrastive_loss_tracker.result(),\n",
    "            \"class_loss\": self.class_loss_tracker.result(),\n",
    "            \"accuracy\": self.acc_metric.result(),\n",
    "            \"roc_auc\": self.roc_auc.result(),\n",
    "            \"pr_auc\": self.pr_auc.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        (x1, x2), (contrast_labels, class_labels) = data\n",
    "        z1, z2, class_logits = self.siamese_model([x1, x2], training=False)\n",
    "\n",
    "        c_loss = contrastive_loss(contrast_labels, z1, z2, margin=self.margin)\n",
    "        class_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        cl_loss = class_loss_fn(class_labels, class_logits)\n",
    "        total_loss = self.lambda_contrast * c_loss + self.lambda_class * cl_loss\n",
    "\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.contrastive_loss_tracker.update_state(c_loss)\n",
    "        self.class_loss_tracker.update_state(cl_loss)\n",
    "        self.acc_metric.update_state(class_labels, class_logits)\n",
    "\n",
    "        # ROC/PR AUC\n",
    "        probs = tf.nn.softmax(class_logits, axis=1)\n",
    "        labels_onehot = tf.one_hot(class_labels, depth=NUM_CLASSES)\n",
    "        self.roc_auc.update_state(labels_onehot, probs)\n",
    "        self.pr_auc.update_state(labels_onehot, probs)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"contrastive_loss\": self.contrastive_loss_tracker.result(),\n",
    "            \"class_loss\": self.class_loss_tracker.result(),\n",
    "            \"accuracy\": self.acc_metric.result(),\n",
    "            \"roc_auc\": self.roc_auc.result(),\n",
    "            \"pr_auc\": self.pr_auc.result(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Keras will reset each metric at the start of each epoch\n",
    "        return [\n",
    "            self.loss_tracker,\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.class_loss_tracker,\n",
    "            self.acc_metric,\n",
    "            self.roc_auc,\n",
    "            self.pr_auc,\n",
    "        ]\n",
    "\n",
    "# Instantiate and compile trainer\n",
    "trainer = AFAContrastiveTrainer(\n",
    "    siamese_model=siamese_model,\n",
    "    margin=MARGIN,\n",
    "    lambda_contrast=LAMBDA_CONTRAST,\n",
    "    lambda_class=LAMBDA_CLASS\n",
    ")\n",
    "trainer.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Train with validation\n",
    "# -------------------------------------------------------\n",
    "trainer.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=30,   # example\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_network.save('/work/users/d/d/ddinh/aaco/models/embedding_classification_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------\n",
    "# Inference / Usage\n",
    "# -------------------------------------------------------\n",
    "# After training, we can use the \"base_network\" to get both embeddings and classification.\n",
    "\n",
    "x_new = np.random.randn(1, num_features).astype(np.float32)\n",
    "x_new_masked = random_feature_mask(x_new, keep_prob=0.7)\n",
    "z_new, class_logits_new = base_network.predict(x_new_masked)\n",
    "print(\"Embedding shape:\", z_new.shape)\n",
    "print(\"Class logits shape:\", class_logits_new.shape)\n",
    "predicted_class = np.argmax(class_logits_new, axis=1)\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
