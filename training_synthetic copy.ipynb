{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 18:34:43.617063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-20 18:34:43.639222: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-20 18:34:43.646015: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 18:34:43.663469: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-20 18:34:48.584078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "sys.path.append('/work/users/d/d/ddinh/aaco/src')\n",
    "from load_dataset import load_adni_data\n",
    "from cvar_sensing.utils import prepare_time_series, batch_interp_nd\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 20, 4) (320, 20, 4) (400, 20, 4)\n",
      "(1280, 20, 1) (320, 20, 1) (400, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/work/users/d/d/ddinh/aaco/input_data/synthetic_data.npz')\n",
    "\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# split into 64/16/20\n",
    "n = len(x)\n",
    "n_train = int(n * 0.64)\n",
    "n_val = int(n * 0.16)\n",
    "n_test = n - n_train - n_val\n",
    "\n",
    "# shuffle\n",
    "idx = np.random.permutation(n)\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "\n",
    "train_x = x[:n_train]\n",
    "train_y = y[:n_train]\n",
    "val_x = x[n_train:n_train + n_val]\n",
    "val_y = y[n_train:n_train + n_val]\n",
    "test_x = x[n_train + n_val:]\n",
    "test_y = y[n_train + n_val:]\n",
    "\n",
    "# concatenate train and val\n",
    "# train_x = np.concatenate((train_x, val_x), axis=0)\n",
    "# train_y = np.concatenate((train_y, val_y), axis=0)\n",
    "\n",
    "num_ts = train_x.shape[1]\n",
    "\n",
    "print(train_x.shape, val_x.shape, test_x.shape)\n",
    "print(train_y.shape, val_y.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([23715,  1885])),\n",
       " (array([0., 1.]), array([5878,  522])),\n",
       " (array([0., 1.]), array([7379,  621])))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y, return_counts=True), np.unique(val_y, return_counts=True), np.unique(test_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts(x, y): \n",
    "    x_data = np.copy(x)\n",
    "    y_data = np.copy(y)\n",
    "    x_ts = []\n",
    "    y_ts = []\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(num_ts):\n",
    "        x_zero = np.zeros(x_data.shape)\n",
    "        x_zero[:, :i+1] = x_data[:, :i+1,:]\n",
    "        \n",
    "        x_filtered = np.transpose(x_zero, (0, 2, 1)).reshape(-1, x_data.shape[1] * x_data.shape[2])\n",
    "        \n",
    "        # zero_mask = np.zeros(x_zero[non_zero_mask,:,:].shape)\n",
    "        # zero_mask[:,:i+1] = 1\n",
    "        # zero_mask = np.transpose(zero_mask, (0, 2, 1)).reshape(-1, x_data.shape[1] * x_data.shape[2])\n",
    "        \n",
    "        # x_filtered = np.concatenate([x_filtered, zero_mask], axis=1)\n",
    "        x_filtered = np.concatenate([x_filtered, np.repeat(i, x_filtered.shape[0])[:, None]], axis=1)\n",
    "        \n",
    "        x_ts.append(x_filtered)\n",
    "        y_ts.append(y_data[:, i, :])\n",
    "        \n",
    "    x_ts = np.concatenate(x_ts, axis=0)\n",
    "    y_ts = np.concatenate(y_ts, axis=0)\n",
    "    \n",
    "    return x_ts, y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25600, 81), (25600, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ts, train_y_ts = get_ts(train_x, train_y)\n",
    "val_x_ts, val_y_ts = get_ts(val_x, val_y)\n",
    "test_x_ts, test_y_ts = get_ts(test_x, test_y)\n",
    "\n",
    "# concatenate train and val\n",
    "# train_x_ts = np.concatenate([train_x_ts, val_x_ts], axis=0)\n",
    "# train_y_ts = np.concatenate([train_y_ts, val_y_ts], axis=0)\n",
    "\n",
    "train_x_ts.shape, train_y_ts.shape\n",
    "# ((7704, 49), (7704, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3770, 81), (3770, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly unsampling the training data so that the number of target with 0 is the same as the number of target with 1 assuming we have more 0\n",
    "mask_0 = train_y_ts[:,0] == 0\n",
    "mask_1 = train_y_ts[:,0] == 1\n",
    "n_1 = np.sum(mask_1)\n",
    "\n",
    "x_0 = train_x_ts[mask_0]\n",
    "y_0 = train_y_ts[mask_0]\n",
    "\n",
    "x_1 = train_x_ts[mask_1]\n",
    "y_1 = train_y_ts[mask_1]\n",
    "\n",
    "np.random.seed(42)\n",
    "idx = np.random.permutation(len(x_0))[:n_1]\n",
    "x_0 = x_0[idx]\n",
    "y_0 = y_0[idx]\n",
    "\n",
    "train_x_ts = np.concatenate([x_0, x_1], axis=0)\n",
    "train_y_ts = np.concatenate([y_0, y_1], axis=0)\n",
    "train_x_ts.shape, train_y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([1885, 1885]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y_ts[:,0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((965120, 81), (965120, 1), (965120, 80))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masksper = 256 \n",
    "d = train_x_ts.shape[1] - 1\n",
    "X_class = np.concatenate([train_x_ts]*masksper, 0)\n",
    "Y_class = np.concatenate([train_y_ts]*masksper, 0)\n",
    "B = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class.shape[0])],\n",
    "1)\n",
    "B = np.float32(B.T)\n",
    "\n",
    "B = np.ones_like(B)\n",
    "\n",
    "zero_mask = X_class[:,:d] == 0\n",
    "B[zero_mask] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero = np.sum(B, axis=1) != 0\n",
    "B = B[mask_nonzero]\n",
    "X_class = X_class[mask_nonzero]\n",
    "Y_class = Y_class[mask_nonzero]\n",
    "\n",
    "X_class[:,:d] = X_class[:,:d] * B\n",
    "X_class.shape, Y_class.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_zero[:, i+1:] = np.nan\n",
    "# x_zero = prepare_input(torch.Tensor([range(0,num_ts)] * x_zero.shape[0]), torch.Tensor(x_zero))[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 81), (32000, 1), (32000, 81))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masksper = 5\n",
    "d = val_x_ts.shape[1]\n",
    "X_class_val = np.concatenate([val_x_ts]*masksper, 0)\n",
    "Y_class_val = np.concatenate([val_y_ts]*masksper, 0)\n",
    "B_val = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class_val.shape[0])],\n",
    "1)\n",
    "B_val = np.float32(B_val.T)\n",
    "\n",
    "B_val = np.ones_like(B_val)\n",
    "\n",
    "# B_val = np.zeros_like(B_val)\n",
    "\n",
    "# B_val[:,-1] = 1\n",
    "# B_val[:, :num_ts*2] = 1\n",
    "\n",
    "# zero_mask_val = X_class_val[:,:d] == 0\n",
    "# B_val[zero_mask_val] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "# mask_nonzero_val = np.sum(B_val, axis=1) != 0\n",
    "# B_val = B_val[mask_nonzero_val]\n",
    "# X_class_val = X_class_val[mask_nonzero_val]\n",
    "# Y_class_val = Y_class_val[mask_nonzero_val]\n",
    "\n",
    "X_class_val[:,:d] = X_class_val[:,:d] * B_val\n",
    "X_class_val.shape, Y_class_val.shape, B_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(max_iter=1000)\n",
    "logistic.fit(X_class, Y_class[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7076076909940175, 0.39228196398212567)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logistic.predict(X_class_val)\n",
    "y_pred_proba = logistic.predict_proba(X_class_val)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "roc_auc_score(Y_class_val[:, 0], y_pred_proba[:, 1]), average_precision_score(Y_class_val[:, 0], y_pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/work/users/d/d/ddinh/aaco/models/logistic.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mmodel\u001b[49m, filename)\n\u001b[1;32m      9\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = '/work/users/d/d/ddinh/aaco/models/logistic.pkl'\n",
    "pickle.dump(logistic, open(filename, 'wb'))\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "import joblib\n",
    "filename = '/work/users/d/d/ddinh/aaco/models/logistic.joblib'\n",
    "joblib.dump(model, filename)\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "location = X_class[:, -1]\n",
    "for m in range(4): \n",
    "    est = XGBClassifier()\n",
    "    input_data = np.concatenate([X_class[:, num_ts*m:num_ts*(m+1)], location[:, None]], axis=1)\n",
    "    est.fit(input_data, Y_class[:,0])\n",
    "    classifiers.append(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6741142372558759 0.34065177959421916\n",
      "0.6498859635057146 0.3377995816659913\n",
      "0.5676595891687819 0.10650301077211803\n",
      "0.5425275623501622 0.09489177900032603\n"
     ]
    }
   ],
   "source": [
    "location_val = X_class_val[:, -1]\n",
    "for m in range(4): \n",
    "    model = classifiers[m]\n",
    "    input_data = np.concatenate([X_class_val[:, num_ts*m:num_ts*(m+1)], location_val[:, None]], axis=1)\n",
    "    y_pred_proba = model.predict_proba(input_data)\n",
    "    print(roc_auc_score(Y_class_val[:, 0], y_pred_proba[:, 1]), average_precision_score(Y_class_val[:, 0], y_pred_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.2, subsample=0.5, colsample_bytree=0.5)\n",
    "est.fit(X_class, Y_class[:, 0])\n",
    "y_pred = est.predict_proba(X_class_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6364494856461982, 0.27161942583241344)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "roc_auc_score(Y_class_val[:, 0], y_pred[:,1]), average_precision_score(Y_class_val[:, 0], y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m29024/29029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6346 - loss: 0.6221 - prc: 0.7205 - roc_auc: 0.6754\n",
      "Epoch 1: val_roc_auc improved from -inf to 0.65998, saving model to /work/users/d/d/ddinh/aaco/models/mlp_interpolation.keras\n",
      "\u001b[1m29029/29029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6346 - loss: 0.6221 - prc: 0.7205 - roc_auc: 0.6754 - val_accuracy: 0.7349 - val_loss: 0.6147 - val_prc: 0.2934 - val_roc_auc: 0.6600\n",
      "Epoch 2/100\n",
      "\u001b[1m28988/29029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6501 - loss: 0.6041 - prc: 0.7451 - roc_auc: 0.7048\n",
      "Epoch 2: val_roc_auc did not improve from 0.65998\n",
      "\u001b[1m29029/29029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1ms/step - accuracy: 0.6501 - loss: 0.6041 - prc: 0.7451 - roc_auc: 0.7048 - val_accuracy: 0.7371 - val_loss: 0.6318 - val_prc: 0.2742 - val_roc_auc: 0.6531\n",
      "Epoch 3/100\n",
      "\u001b[1m29018/29029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6558 - loss: 0.5975 - prc: 0.7534 - roc_auc: 0.7152\n",
      "Epoch 3: val_roc_auc did not improve from 0.65998\n",
      "\u001b[1m29029/29029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.6558 - loss: 0.5975 - prc: 0.7534 - roc_auc: 0.7152 - val_accuracy: 0.7520 - val_loss: 0.6054 - val_prc: 0.2473 - val_roc_auc: 0.6518\n",
      "Epoch 4/100\n",
      "\u001b[1m 8505/29029\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.6604 - loss: 0.5928 - prc: 0.7587 - roc_auc: 0.7211"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 67\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, accuracy, roc_auc\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# history = train_model(model, train_x_ts, train_y_ts, val_x_ts, val_y_ts)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# evaluate_model(model, val_x_ts, val_y_ts)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_class_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_class_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m evaluate_model(model, X_class_val, Y_class_val)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_history\u001b[39m(history):\n",
      "Cell \u001b[0;32mIn[11], line 50\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, epochs, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     43\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_roc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     44\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     45\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \n\u001b[1;32m     46\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/device:GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# class_weight = {0: 1.0, 1: 10.0} \u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "TOTAL_FEATURES = train_x_ts.shape[-1]\n",
    "HIDDEN_DIM = 15\n",
    "NUM_CLASSES = 1 \n",
    "DROPOUT_RATE = 0.75\n",
    "\n",
    "def create_mlp():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(TOTAL_FEATURES,)),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        # layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        # layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        # layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        layers.Dense(NUM_CLASSES, activation='sigmoid') \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = create_mlp()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', AUC(name='roc_auc'), AUC(name='prc', curve='PR')]\n",
    ")\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        '/work/users/d/d/ddinh/aaco/models/mlp_interpolation.keras',  \n",
    "        monitor='val_roc_auc',\n",
    "        mode='max',  \n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_roc_auc', \n",
    "        mode='max', \n",
    "        patience=10,  \n",
    "        verbose=1\n",
    "    )\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        # class_weight = {0: 1.0, 1: 10.0} \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[checkpoint, early_stopping],\n",
    "            verbose=1, \n",
    "        )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    loss, accuracy, roc_auc, prc = model.evaluate(X, y, verbose=0)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}, ROC AUC: {roc_auc}, PRC: {prc}\")\n",
    "    return loss, accuracy, roc_auc\n",
    "\n",
    "# history = train_model(model, train_x_ts, train_y_ts, val_x_ts, val_y_ts)\n",
    "# evaluate_model(model, val_x_ts, val_y_ts)\n",
    "history = train_model(model, X_class, Y_class, X_class_val, Y_class_val)\n",
    "evaluate_model(model, X_class_val, Y_class_val)\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['roc_auc'])\n",
    "    plt.plot(history.history['val_roc_auc'])\n",
    "    plt.title('model roc_auc')\n",
    "    plt.ylabel('roc_auc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['prc'])\n",
    "    plt.plot(history.history['val_prc'])\n",
    "    plt.title('model prc')\n",
    "    plt.ylabel('prc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_history(history)\n",
    "#  val_prc: 0.5998 - val_roc_auc: 0.7917\n",
    "# val_accuracy: 0.5886 - val_loss: 0.8313 - val_prc: 0.5985 - val_roc_auc: 0.7912\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/1000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 22ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6563152100370366, 0.2648546135654762)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "pred = model.predict(X_class_val)\n",
    "roc_auc_score(Y_class_val, pred), average_precision_score(Y_class_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 1), (32000, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_class_val.shape, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_class)\n",
    "X_test = scaler.transform(X_class_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m58101/58101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 850us/step - accuracy: 0.6285 - loss: 0.7117 - prc: 0.7100 - roc_auc: 0.6654 - val_accuracy: 0.8244 - val_loss: 0.5892 - val_prc: 0.3091 - val_roc_auc: 0.6689\n",
      "Epoch 2/100\n",
      "\u001b[1m58101/58101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 836us/step - accuracy: 0.6483 - loss: 0.6162 - prc: 0.7383 - roc_auc: 0.6975 - val_accuracy: 0.8165 - val_loss: 0.5960 - val_prc: 0.3103 - val_roc_auc: 0.6703\n",
      "Epoch 3/100\n",
      "\u001b[1m58101/58101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 841us/step - accuracy: 0.6505 - loss: 0.6131 - prc: 0.7435 - roc_auc: 0.7041 - val_accuracy: 0.8156 - val_loss: 0.6057 - val_prc: 0.3086 - val_roc_auc: 0.6658\n",
      "Epoch 4/100\n",
      "\u001b[1m18886/58101\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 828us/step - accuracy: 0.6534 - loss: 0.6108 - prc: 0.7455 - roc_auc: 0.7078"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, AUC(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m), AUC(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprc\u001b[39m\u001b[38;5;124m'\u001b[39m, curve\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPR\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_class_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:140\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1507\u001b[0m, in \u001b[0;36mConcreteFunction.captured_inputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcaptured_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns external Tensors captured by this function.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124;03m  self.__call__(*args) passes `args + self.captured_inputs` to the function.\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_captured_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/util/nest.py:293\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.flatten\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(structure, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a flat list from a given structure.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    TypeError: The nest is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/util/nest_util.py:712\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(modality, structure, expand_composites)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Flattens a nested structure.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m  TypeError: The nest is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m--> 712\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m    714\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_flatten(structure)\n",
      "File \u001b[0;32m/work/users/d/d/ddinh/.venv/lib64/python3.11/site-packages/tensorflow/python/util/nest_util.py:726\u001b[0m, in \u001b[0;36m_tf_core_flatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    724\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    725\u001b[0m expand_composites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),  # Hidden layer\n",
    "    tf.keras.layers.Dropout(0.2),  # Dropout for regularization\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer (sigmoid for binary classification)\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy', AUC(name='roc_auc'), AUC(name='prc', curve='PR')])\n",
    "history = model.fit(X_train, Y_class, epochs=100, validation_data=(X_test, Y_class_val), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "TOTAL_FEATURES = train_x_ts.shape[-1]\n",
    "HIDDEN_DIM = 20\n",
    "NUM_CLASSES = 1 \n",
    "DROPOUT_RATE = 0.5\n",
    "\n",
    "def create_mlp():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(TOTAL_FEATURES,)),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(HIDDEN_DIM, activation='relu'),\n",
    "        layers.Dropout(DROPOUT_RATE),\n",
    "        layers.Dense(NUM_CLASSES, activation='sigmoid') \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = create_mlp()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', AUC(name='roc_auc'), AUC(name='prc', curve='PR')]\n",
    ")\n",
    "\n",
    "def train_model(model, X_train, y_train, epochs=20, batch_size=32):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    loss, accuracy, roc_auc, prc = model.evaluate(X, y, verbose=0)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}, ROC AUC: {roc_auc}, PRC: {prc}\")\n",
    "    return loss, accuracy, roc_auc\n",
    "\n",
    "history = train_model(model, train_x_ts, train_y_ts)\n",
    "evaluate_model(model, X_class_val, Y_class_val)\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['roc_auc'])\n",
    "    plt.title('model roc_auc')\n",
    "    plt.ylabel('roc_auc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['prc'])\n",
    "    plt.title('model prc')\n",
    "    plt.ylabel('prc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_adni_data()\n",
    "x = dataset.x\n",
    "y = dataset.y\n",
    "\n",
    "mask_nan = np.isnan(x)\n",
    "\n",
    "x[mask_nan] = 0\n",
    "\n",
    "num_ts = y.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06387226 0.64271457 0.29341317]\n",
      "[0.08805668 0.61234818 0.29959514]\n",
      "[0.10761421 0.59187817 0.30050761]\n",
      "[0.125      0.58974359 0.28525641]\n",
      "[0.16613757 0.54179894 0.29206349]\n",
      "[0.13573883 0.56872852 0.29553265]\n",
      "[0.178125  0.5796875 0.2421875]\n",
      "[0.18283582 0.53731343 0.27985075]\n",
      "[0.17350746 0.46455224 0.3619403 ]\n",
      "[0.18235294 0.45294118 0.36470588]\n",
      "[0.18596491 0.49473684 0.31929825]\n",
      "[0.17098446 0.43005181 0.39896373]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_ts):\n",
    "    count = [0,0,0]\n",
    "    total = 0\n",
    "    for j in range(y.shape[0]):\n",
    "        for k in range(3):\n",
    "            if y[j,i,k] == 1:\n",
    "                count[k] += 1\n",
    "                total += 1\n",
    "    count = np.array(count)\n",
    "    print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13054449 0.56998672 0.29946879]\n"
     ]
    }
   ],
   "source": [
    "count = [0,0,0]\n",
    "total = 0\n",
    "for i in range(num_ts):\n",
    "    for j in range(y.shape[0]):\n",
    "        for k in range(3):\n",
    "            if y[j,i,k] == 1:\n",
    "                count[k] += 1\n",
    "                total += 1\n",
    "count = np.array(count)\n",
    "print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40976380572188953"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_nan = x==0\n",
    "# get the number of nan values\n",
    "total = mask_nan.sum()\n",
    "probability = total / x.size\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((801, 12, 4), (201, 12, 4), (801, 12, 3), (201, 12, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into train and test sets 80/20 with random seed 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = prepare_time_series(torch.Tensor([range(0,12)] * x_train.shape[0]), torch.Tensor(x_train))[1]\n",
    "y_train = prepare_time_series(torch.Tensor([range(0,12)] * y_train.shape[0]), torch.Tensor(y_train))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3297,  0.1390,  1.3199, -0.0833],\n",
       "        [ 0.3297,  0.1390,  1.0883,  0.3012],\n",
       "        [ 0.3297,  0.1390,  0.9298, -0.1822],\n",
       "        [ 0.3297,  0.1390,  0.9298, -0.1822],\n",
       "        [ 0.3297,  0.0346,  0.9745,  0.2414],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3297,  0.0346,  0.9745,  0.2414],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.3297,  0.4605,  0.9745,  0.2414],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = torch.cat([x_train, x_train[:, [-1]]], dim=-2).numpy()\n",
    "# y_train = torch.cat([y_train, y_train[:, [-1]]], dim=-2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.round(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ts = []\n",
    "# y_ts = []\n",
    "\n",
    "# for i in range(num_ts): \n",
    "#     x_temp = np.zeros_like(x_train)\n",
    "#     x_temp[:, :i+1, :] = x_train[:, :i+1, :]\n",
    "#     x_ts.append(x_temp)    \n",
    "#     y_ts.append(y_train)\n",
    "# x_ts = np.concatenate(x_ts, axis=0)\n",
    "# y_ts = np.concatenate(y_ts, axis=0)\n",
    "# x_ts.shape, y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"temp\n",
    "\"\"\"\n",
    "x_ts = x_train\n",
    "y_ts = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "for item in x_ts:\n",
    "    x_all.append(item.flatten('F'))\n",
    "x_train = np.array(x_all)\n",
    "y_train = y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_masks(inputs, pm=0.2, pd_m=0.4):\n",
    "    inputs = np.copy(inputs).reshape(-1, 12, 4)\n",
    "    n, T, M = inputs.shape\n",
    "    masked_inputs = inputs.copy()\n",
    "\n",
    "    mask_m1 = np.random.binomial(1, pm, size=(n, T, M))\n",
    "    \n",
    "    t_max = np.random.randint(0, T, size=n)\n",
    "    mask_m2 = np.ones((n, T, M))\n",
    "    for i in range(n):\n",
    "        mask_m2[i, t_max[i]:] = 0\n",
    "    \n",
    "    modality_drop = np.random.binomial(1, pd_m, size=(n, M))\n",
    "    mask_m3 = np.ones((n, T, M))\n",
    "    for m in range(M):\n",
    "        mask_m3[:, :, m] *= modality_drop[:, m].reshape(-1, 1)\n",
    "\n",
    "    final_mask = mask_m1 * mask_m2 * mask_m3\n",
    "    masked_inputs *= final_mask\n",
    "\n",
    "    return masked_inputs, final_mask.reshape(n, -1)\n",
    "\n",
    "pm = 0.2\n",
    "pd_m = 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masksper = 256 * 2\n",
    "d = x_train.shape[1]\n",
    "X_class = np.concatenate([x_train]*masksper, 0)\n",
    "Y_class = np.concatenate([y_train]*masksper, 0)\n",
    "# B = np.concatenate(\n",
    "# [np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class.shape[0])],\n",
    "# 1)\n",
    "# B = np.float32(B.T)\n",
    "\n",
    "_, B = apply_masks(X_class, pm, pd_m)\n",
    "    \n",
    "\"\"\"\n",
    "remove for interpolation\n",
    "\"\"\"\n",
    "zero_mask = X_class == 0\n",
    "B[zero_mask] = 0\n",
    "\n",
    "# # remove 0 mask\n",
    "mask_nonzero = np.sum(B, axis=1) != 0\n",
    "B = B[mask_nonzero]\n",
    "X_class = X_class[mask_nonzero]\n",
    "Y_class = Y_class[mask_nonzero]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_nan = X_class == 0\n",
    "# B[mask_nan] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = np.concatenate((X_class*B, B), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class.shape, Y_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "for i in range(B.shape[0]):\n",
    "    b = B[i]\n",
    "    temp = -1\n",
    "    for j in range(4):\n",
    "        part = b[num_ts*j:num_ts*(j+1)]\n",
    "        max_index = np.where(part == 1)[0]\n",
    "        if len(max_index) > 0:\n",
    "            max_index = max_index[-1]\n",
    "            if max_index > temp:\n",
    "                temp = max_index\n",
    "    location.append(temp)\n",
    "    \n",
    "location = np.array(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(location, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = []\n",
    "for i in range(Y_class.shape[0]):\n",
    "    y_location = Y_class[i, location[i]]\n",
    "    mask_nan = np.isnan(y_location)\n",
    "    y_location[mask_nan] = 0\n",
    "    y_temp.append(y_location)\n",
    "y_temp = np.array(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove y with nan values\n",
    "mask_zero = np.sum(y_temp, axis=1) != 0\n",
    "X_class = X_class[mask_zero]\n",
    "Y_class = y_temp[mask_zero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_class = np.argmax(Y_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "est = XGBClassifier(n_estimators=256, device='gpu')\n",
    "est.fit(X_class, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est.save_model('/work/users/d/d/ddinh/aaco/models/adni_different_masking.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts_val = []\n",
    "y_ts_val = []\n",
    "\n",
    "for i in range(num_ts): \n",
    "    x_temp = np.zeros_like(x_val)\n",
    "    x_temp[:, :i+1, :] = x_val[:, :i+1, :]\n",
    "    x_ts_val.append(x_temp)    \n",
    "    y_ts_val.append(y_val)\n",
    "x_ts_val = np.concatenate(x_ts_val, axis=0)\n",
    "y_ts_val = np.concatenate(y_ts_val, axis=0)\n",
    "x_ts_val.shape, y_ts_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_val = []\n",
    "for item in x_ts_val:\n",
    "    x_all_val.append(item.flatten('F'))\n",
    "x_val = np.array(x_all_val)\n",
    "y_val = y_ts_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masksper = 1\n",
    "d = x_val.shape[1]\n",
    "X_class_val = np.concatenate([x_val]*masksper, 0)\n",
    "Y_class_val = np.concatenate([y_val]*masksper, 0)\n",
    "B_val = np.concatenate(\n",
    "[np.sum(np.random.permutation(np.eye(d))[:, :np.random.randint(d)], 1, keepdims=True) for _ in range(X_class_val.shape[0])],\n",
    "1)\n",
    "B_val = np.float32(B_val.T)\n",
    "\n",
    "# B_val = np.ones_like(B_val)\n",
    "\n",
    "zero_mask_val = X_class_val == 0\n",
    "B_val[zero_mask_val] = 0\n",
    "\n",
    "# remove 0 mask\n",
    "mask_nonzero_val = np.sum(B_val, axis=1) != 0\n",
    "B_val = B_val[mask_nonzero_val]\n",
    "X_class_val = X_class_val[mask_nonzero_val]\n",
    "Y_class_val = Y_class_val[mask_nonzero_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_val = []\n",
    "for i in range(B_val.shape[0]):\n",
    "    b = B_val[i]\n",
    "    temp = -1\n",
    "    for j in range(4):\n",
    "        part = b[num_ts*j:num_ts*(j+1)]\n",
    "        max_index = np.where(part == 1)[0]\n",
    "        if len(max_index) > 0:\n",
    "            max_index = max_index[-1]\n",
    "            if max_index > temp:\n",
    "                temp = max_index\n",
    "    location_val.append(temp)\n",
    "    \n",
    "location_val = np.array(location_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp_val = []\n",
    "for i in range(Y_class_val.shape[0]):\n",
    "    y_location_val = Y_class_val[i, location_val[i]]\n",
    "    mask_nan_val = np.isnan(y_location_val)\n",
    "    y_location_val[mask_nan_val] = 0\n",
    "    y_temp_val.append(y_location_val)\n",
    "y_temp_val = np.array(y_temp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove y with nan values for validation set\n",
    "mask_zero_val = np.sum(y_temp_val, axis=1) != 0\n",
    "X_class_val = X_class_val[mask_zero_val]\n",
    "Y_class_val = y_temp_val[mask_zero_val]\n",
    "B_val = B_val[mask_zero_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_zero_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_val = np.concatenate((X_class_val*B_val, B_val), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = est.predict_proba(X_class_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.argmax(val_preds, 1)==np.argmax(Y_class_val, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is temoprary evaluation, since it's not really correct.\n",
    "# it should be evaluated on the accumulated predictions, not the individual predictions like this rolling out \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "pr_auc_macro = average_precision_score(Y_class_val, val_preds, average=\"macro\")\n",
    "print(pr_auc_macro)\n",
    "\n",
    "roc_auc_macro = roc_auc_score(Y_class_val, val_preds, average=\"macro\", multi_class=\"ovr\")\n",
    "print(roc_auc_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(B_val.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "# 0.5057228523811975\n",
    "# 0.6798018971723648\n",
    "\n",
    "# masking from a2mt paper\n",
    "# 0.5109105973299515\n",
    "# 0.7030657167468642"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
